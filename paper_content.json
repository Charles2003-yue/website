{
  "original_text": "Bandit based Dynamic Candidate Edge Selection in Solving Traveling\nSalesman Problems\nLong Wanga,âˆ—, Jiongzhi Zhenga,âˆ—, Zhengda Xionga,âˆ—, ChuMin Liband Kun Hea,âˆ—âˆ—\naSchool of Computer Science and Technology, Huazhong University of Science and Technology, China 430074\nbMIS, University of Picardie Jules Verne, France 80039\nARTICLE INFO\nKeywords :\nTraveling salesman problems\nMulti-armed bandit\nCandidate set\nLin-Kernighan-Helsgaun algorithm\nLocal searchABSTRACT\nAlgorithmsdesignedforroutingproblemstypicallyrelyonhigh-qualitycandidateedgestoguidetheir\nsearch, aimingto reduce thesearch space andenhance the searchefficiency. However, manyexisting\nalgorithms, like the classical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman\nProblem(TSP),oftenusepredeterminedcandidateedgesthatremainstaticthroughoutlocalsearches.\nThisrigiditycouldcausethealgorithmtogettrappedinlocaloptima,limitingitspotentialtofindbetter\nsolutions. To address this issue, we propose expanding the candidate sets to include other promising\nedges, providing them an opportunity for selection. Specifically, we incorporate multi-armed bandit\nmodels to dynamically select the most suitable candidate edges in each iteration, enabling LKH\nto make smarter choices and lead to improved solutions. Extensive experiments on multiple TSP\nbenchmarks show the excellent performance of our method. Moreover, we employ this bandit-based\nmethod to LKH-3, an extension of LKH tailored for solving various TSP variant problems, and our\nmethod also significantly enhances LKH-3â€™s performance across typical TSP variants.\n1. Introduction\nThe Traveling Salesman Problem (TSP) is a classic NP-\nhard combinatorial optimization problem. Given an undi-\nrected complete graph where the distance between each\npair of vertices (i.e., cities) is known, TSP aims to find the\nshortestpaththatstartsfromastartingcity,passeseachcity\nexactly once, and then returns to the starting city. As the\nbasic problem of many routing problems [1, 2, 3, 4, 5, 6],\nTSP also has many practical applications [7, 8].\nHeuristic algorithms are known to be most efficient for\nsolvingtheTSP,andtheycanbedividedintotwocategories:\nglobal search and local search. Global search methods [9]\nattempt to explore a wide solution space with a global\nperspective incorporating entropy in individual selection\nand partial crossover which are impressive in genetic al-\ngorithm [10, 11]. However, it is hard and time-consuming\nfor them to tackle super-large instances with huge solution\nspaces. Local search methods always maintain the current\nsolution and explore its neighborhood space, which are\nefficient and suitable for instances with various scales. In\nthispaper,wemainlyfocusonlocalsearchmethods,among\nwhichtheLin-Kernighan-Helsgaun(LKH)[12]algorithmis\noneofthemostrepresentativeandbest-performingmethods.\nTheLKHalgorithmisanoutstandingmethodamongthe\nLin-Kernighan(LK)[13]seriesthatcollectssomepromising\nedgesinthecandidatesetsofeachcityduringinitialization.\nWhen using the local search operators, such as ğ‘˜-opt, to\nadjustthecurrentsolution,theLK-basedalgorithmsrestrict\nâˆ—The first three authors contributed equally.\nâˆ— âˆ—Corresponding author.\nm202273734@hust.edu.cn (L. Wang); jzzheng@hust.edu.cn (J.\nZheng); xiongzd@hust.edu.cn (Z. Xiong); chumin.li@u-picardie.fr (C. Li);\nbrooklet60@hust.edu.cn (K. He)\nORCID(s):0000-0001-7627-4604 (K. He)the new edges to be added to belong to the candidate sets.\nTherefore, the algorithm performance heavily depends on\nthe quality of the candidate edges. LKH proposes an ef-\nfective metric called ğ›¼-value calculated based on a 1-tree\nstructure to select the candidate edges [14], resulting in its\nexcellent performance.\nHowever, the candidate edges in LKH are generally\npredetermined in the initialization stage and then keep un-\nchangedduringthesearchingprocess.Therefore,thecontent\nof each cityâ€™s candidate edges is relatively fixed, and LKH\nonlyassociateseachcitywithaboutafixednumberofcandi-\ndateedges(5bydefault).Althoughthe ğ›¼-valueispromising\nin evaluating the quality of the edges, once some crucial\nedges in the optimal solution are missed by the collected\ncandidate edges, it is hard for LKH to reach the global\noptimum. Simply enlarging the candidate sets allows the\nalgorithm to consider more edges, which, however, reduces\nthe efficiency significantly and may also contain some low-\nquality edges to mislead the search directions.\nIn this paper, we propose a novel method based on\nreinforcementlearningtoimprovetheLKHalgorithm,help-\ning it select the candidate edges more smartly and flexibly,\nproviding more edges the opportunity to serve as candidate\nedges. Specifically, we first expand the candidate sets of\neach city to a larger size and then select a subset of edges\nfrom the candidate sets to serve as candidate edges during\neach iteration. We associate each city with a multi-armed\nbandit(MAB),whereeacharmcorrespondstoanedgeinits\nenlarged candidate set and is associated with an evaluation\nvalue,denotedas ğ‘€-value.Theğ‘€-valueofanarmindicates\nthe benefit of selecting it as a candidate edge. The bandit\nmodels can learn from the searching process and update\ntheğ‘€-values. In each iteration of the algorithm, the bandit\nWang et al.: Preprint submitted to Elsevier Page 1 of 12arXiv:2505.15862v1 [cs.AI] 21 May 2025\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nmodelsrecommendappropriatecandidateedgesforthelocal\nsearch.\nMoreover,weemploythreedifferentstrategiesforselect-\ningthecandidateedges,i.e.,thearmsofthebandit.Thefirst\nstrategyappliesthe ğœ–-greedymethodtotrade-offexploration\nand exploitation, while the other two make the selection\ngreedily based on the ğ‘€-values andğ›¼-values, respectively.\nThethreestrategiesareusedcooperativelyduringthesearch\nto improve the robustness.\nWe apply our proposed method to LKH, denoting the\nresulting algorithm as Bandit-based LKH (bandLKH). Our\nmethod expands the searching space, providing higher flex-\nibility for the search, assisting the LKH algorithm in es-\ncaping local optima and finding better solutions. We com-\npare bandLKH with the LKH baseline, as well as VSR-\nLKH[15]andNeuroLKH[16],tworepresentativelearning-\nbased algorithms. Extensive experiments in various bench-\nmarks show the superiority of bandLKH over LKH, VSR-\nLKH, and NeuroLKH. In particular, our method exhibits\nbetterperformanceandrobustnessthansimplyenlargingthe\ncandidate sets in LKH. The results indicate that our MAB\nmethod can effectively and smartly suggest high-quality\nedges and ignore low-quality ones.\nWe further apply our MAB method to the LKH-3 al-\ngorithm [17], an extension of LKH that can solve many\nTSP variant problems efficiently. The resulting algorithm is\ndenoted as bandLKH-3. We select two representative vari-\nant problem called Multiple Traveling Salesmen Problem\n(MTSP)andCapacitatedVehicleRoutingProblem(CVRP),\nandcompareourbandLKH-3withLKH-3.Theresultsshow\nthat our method can also significantly improve LKH-3 in\nMTSP and CVRP, indicating its excellent generalization\ncapability.\nThe main contributions of this paper are as follows.\nâ€¢We identified relatively rigid designs in the LKH\nalgorithm, i.e., the candidate edges for each city are\nrelatively fixed. We construct MAB models to select\nhigh-quality candidate edges adaptively during the\nsearching process from enlarged candidate sets. We\npropose three policies to choose candidates coordi-\nnately and a framework to train and utilize the MAB\nmodels. Our proposed methods and framework can\nbe applied to other heuristic algorithms for routing\nproblems needing to select candidate edges.\nâ€¢WecomparebandLKHwithLKHaswellasrepresen-\ntative learning-based algorithms for TSP on various\nbenchmarks.WealsogeneralizeourmethodtoLKH-\n3, which is an extension version of LKH for various\nTSP variants. Extensive experiments show the excel-\nlent performance and generalization capability of our\nmethod in TSP and its variant problems, MTSP and\nCVRP.\n2. Problem Definition\nIn this section, we present the definition of the involved\nproblems,includingtheTravelingSalesmanProblem(TSP),the Multiple TSP (MTSP), and the Capacitated Vehicle\nRouting Problem (CVRP).\n2.1. Traveling Salesman Problem\nGiven an undirected complete graph G(V,E), V is made\nup of cities in G numbered 1, 2, ..., n and E contains all\npairwise edges such as edge between city i and j presented\nby (i, j) which has its cost d(i,j). The aim is to find an\nhamiltonian circuit with a minimum total cost caculated byâˆ‘ğ‘›âˆ’1\nğ‘–=1(ğ‘‘(ğ‘–,ğ‘–+ 1)) +ğ‘‘(ğ‘›,1).\n2.2. Multiple TSP\nIn the MTSP, a set of ğ‘šsalesmen (or vehicles) are\navailable to visit a set of ğ‘›cities and each salesman starts\nand ends their route at a designated depot, with each city\nneeding to be visited exactly once by one of the salesmen.\nLetğ‘†= {1,2,â€¦,ğ‘š}be the set of salesmen and ğ¶=\n{1,2,â€¦,ğ‘›}bethesetofcities. ğ‘‡1,ğ‘‡2,â€¦,ğ‘‡ğ‘šarecomposed\nofğ‘šsubsetsğ¶1,ğ¶2,â€¦,ğ¶ğ‘šinğ¶. The goal is to minimizeâˆ‘ğ‘š\nğ‘˜=1âˆ‘\n(ğ‘–,ğ‘—)âˆˆğ‘‡ğ‘˜ğ‘‘(ğ‘–,ğ‘—).\n2.3. Capacitated Vehicle Routing Problem\nIn the CVRP, define m homogeneous fleets serving n\ncities have a max capacity ğ‘which could not be exceeded\nin each vehicle. Due to capacity, n cities are divided into m\nexclusive parts represented by ğ‘‡1,ğ‘‡2,â€¦,ğ‘‡ğ‘šbesides com-\nmonstartingandendingcities.Eachcustomerin ğ‘‡ğ‘–isvisited\nexactly once by one of the vehicles and common cities can\nbe visited many times. The total distance traveled by all\nvehicles,âˆ‘ğ‘š\nğ‘˜=1âˆ‘\n(ğ‘–,ğ‘—)âˆˆğ‘‡ğ‘˜ğ‘‘(ğ‘–,ğ‘—), is minimized.\n3. Related Work\nIn this section, we first review some related studies that\nsolve TSP with learning-based methods and then briefly\nintroduce some key components used in LKH.\n3.1. Learning-based Methods\nRecently, the application of learning-based methods,\nsuch as reinforcement learning and deep learning, for com-\nbinatorial optimization problems has become a highlight of\nresearch. TSP has even become a touchstone and one of the\nmost popular problems for learning-based methods.\nLearning-basedmethodsforTSPcanberoughlydivided\ninto two categories depending on whether deep learning\nis adopted. Actually, most learning-based methods try to\napplydeeplearningmethodsforTSPsolving.Typicalmeth-\nods include deep reinforcement learning and supervised\nlearning. For instance, some studies design or apply novel\ndeep learning structures for solving TSP, such as the multi-\npointer Transformer architecture called Pointerformer [18]\nand the hierarchical deep reinforcement learning frame-\nwork [19]. Some studies train neural networks to automate\nthe heuristic design, such as the Ant Colony Optimization\nandğ‘˜-opt[20,21,22]heuristics.TheNeuroLKHalgorithm\nutilizes a Sparse Graph Network to select candidate edges\nfor LKH [16], showing excellent performance in instances\nWang et al.: Preprint submitted to Elsevier Page 2 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nwithlessthan6,000cities.Aigerimproposeahybridmodel\ncombining an attention-based encoder and a Long Short-\nTermMemory(LSTM)decoderaddressingthechallengeof\nrouting a heterogeneous fleet. [23]. Bresson trains via deep\nreinforcementlearning,effectivelyaddressesthecombinato-\nrialoptimizationchallengesoftheTSP[24].GRLOS-Muses\nGraph Neural Networks to improve Adaptive Large Neigh-\nbourhood Search [25]. There are also some other famous\nmodelsandalgorithmsusingdeeplearningforTSP,suchas\nS2V-DQN [26], POMO [27], GLOP [28], etc.\nThe deep learning-based methods provide many new\nand interesting perspectives for solving TSP. However, they\nare usually hard to scale to large instances with tens of\nthousands of cities. The other category of method usually\nuses traditional reinforcement learning to accumulate the\nlearning information in tables and use them to guide the\nsearch.traditionalreinforcementlearningplaysanimportant\npartroleinTSP.MazyavkinasummarizedtheTSPproblem\nbasedonreinforcementlearning[29].Forexample,theAnt-\nQ [30] and Q-ACS [31] replace the pheromone in the ant\ncolony algorithm with the Q-table in the Q-learning algo-\nrithm.TheRMGAalgorithm[32]usesreinforcementlearn-\ning to construct mutation individuals in genetic algorithms.\nRLHEA combines Q-learning method with hybrid evolu-\ntionary algorithm for routing problem [33]. Moreover, the\nVSR-LKH [15] algorithm combines typical reinforcement\nlearning methods with LKH, altering and reordering the\ncandidateedges,showingexcellentperformanceinTSP.Re-\ninforcementlearningalsohasmanyopportunitiesinsolving\nstochastic dynamic vehicle routing problem [34].\nOur proposed method uses MAB models to select and\nadjust candidate edges during the local search. Compared\nto NeuroLKH and VSR-LKH, which also select and deter-\nmine the candidate edges before the local search process,\nour method provides more opportunity for other promising\nedges to be contained in candidate sets, allowing the algo-\nrithm to effectively solve instances with various scales and\nstructures.\n3.2. Key Components in LKH\n3.2.1. Theğ›¼-value\nCandidate edges are very important for LK-based local\nsearch algorithms since they decide the new edges that can\nbe added to the maintained solution. LKH proposes the ğ›¼-\nvalue for evaluating the edges and selecting the candidate\nedges. Theğ›¼-value is calculated based on a 1-tree struc-\nture [14], a variant of the spanning tree. Given a graph\nğº= (ğ‘‰,ğ¸), for any vertex ğ‘£âˆˆğ‘‰, we can generate a\n1-tree by first constructing a spanning tree on ğ‘‰âˆ–{ğ‘£}and\nthencombiningitwithtwoedgesfrom ğ¸incidenttoğ‘£.The\nminimum1-treeisthe 1-treewiththeminimumlength,i.e.,\nthe total length of its edges. We denote ğ¿(ğ‘‡)as the length\nof the minimum 1-tree, which is obviously a lower bound\nof the length of the shortest TSP tour. Moreover, we denote\nğ¿(ğ‘‡(ğ‘–,ğ‘—))as the length of the minimum 1-tree containing\nedge (ğ‘–,ğ‘—).Theğ›¼-valueofedge (ğ‘–,ğ‘—)iscalculatedasfollows.\n1\n2\n4 35\n6(a) Sequential 3-opt\nğ‘8\nğ‘3ğ‘4\nğ‘6ğ‘5ğ‘2ğ‘1ğ‘7 (b) Non-sequential 4-opt\nFigure 1: Examples of sequential and non-sequential ğ‘˜-opt\nmoves.\nğ›¼(ğ‘–,ğ‘—) =ğ¿(ğ‘‡(ğ‘–,ğ‘—)) âˆ’ğ¿(ğ‘‡). (1)\nTo further enhance the performance of ğ›¼-values, LKH\napplies the method of adding penalties [35] to vertices to\nobtain a tighter lower bound.\n3.2.2. Search Operators\nThe core search operator in LKH is the famous ğ‘˜-opt\nmethod,whichreplaces ğ‘˜edgesinthecurrentsolutionwith\nğ‘˜newedgesbasedontheejectchainmethod.Thatis,remove\nğ‘˜edges in the tour and attempt to rearrange the order of\nconnectionsamongthesepointstofindabettersolution.The\nğ‘˜-opt operator in LKH contains two categories, sequential\nandnon-sequentialmoves,asshowninFigure1.Thedashed\nlineistheedgethatisabouttobedisconnected.Thesequen-\ntial move starts from a starting point, e.g., ğ‘1, alternatively\nselects the edges to be removed, e.g., (ğ‘1,ğ‘2),(ğ‘3,ğ‘4)and\n(ğ‘5,ğ‘6), and edges to be added, e.g., (ğ‘2,ğ‘3)and(ğ‘4,ğ‘5),\nandguaranteesthatafterselectingeachedgetoberemoved,\nconnecting its endpoint, e.g., ğ‘4andğ‘6, back to the starting\npoint leads to a feasible TSP tour. Therefore, the sequential\nmove can be stopped once an improvement is found, and\nthe non-sequential move cannot. The non-sequential move\ncombines two distinct infeasible ğ‘˜-opt moves to form a\nfeasible tour, as shown in Figure 1(b). It is a supplement of\nthe sequential move, exploring additional search space that\nsequential moves cannot reach.\nIn summary, the search operators in LKH are encapsu-\nlated in the LinKernighan() function, which is an important\npartofexecutingLKalgorithm[13],followingtheguidance\nof the candidate edges to find moves that can improve the\ncurrentsolution.LinKernighan()finallyreturnsalocalopti-\nmalsolutionthatcannotbeimprovedbyanysearchoperators\nwith the candidate edges. For the detailed implementations\nof the LinKernighan() function, we referred to [12].\n4. Method\nThissectionpresentsourproposedbandLKHalgorithm.\nWefirstintroduceourmethodofusingmulti-armedbandits\n(MAB)toselectandrecommendcandidateedgesforthelo-\ncal search algorithm, then introduce the main framework of\nWang et al.: Preprint submitted to Elsevier Page 3 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nbandLKH, and finally introduce the method for calculating\nthe rewards and updating the bandit models.\n4.1. Candidate Edges Selection\nAs described in the introduction, our proposed MAB\nmodels select high-quality candidate edges from the en-\nlargedcandidatesets.NotethatLKHrestrictsthemaximum\nedges contained in each candidate set using a constant pa-\nrameterğ¶ğ‘šğ‘ğ‘¥,whosedefaultvalueis5.Suchadefaultvalue\nfits well with the algorithm, as a smaller value significantly\nreduces the search ability, and a larger value may contain\nlow-qualityedgesandreducethesearchefficiency.However,\nthe restriction of ğ¶ğ‘šğ‘ğ‘¥= 5may also miss some promising\nedges. Therefore, we propose to enlarge each candidate set\ntoalargersize(setting ğ¶ğ‘šğ‘ğ‘¥= 7bydefault),allowingmore\nedges to serve as candidate edges, and further use an MAB\nto ignore low-quality edges and select appropriate edges in\neach candidate set.\nIn the experiments, we perform an empirical analysis\nto evaluate the benefit of the expansion of candidate sets\nand a comparison showing that using our MAB to select\ncandidate edges from the enlarged candidate sets is more\nrobust and effective than regarding all edges in the enlarged\ncandidate sets as candidate edges directly, indicating the\nexcellent performance of our method.\nIn the following, we first introduce the proposed MAB\nmodelandthenthemethodofpullingthearmsinthebandit\nmodels.\n4.1.1. The MAB Model\nGiven the enlarged candidate set of each city, directly\nregarding all its edges as candidate edges will significantly\nreduce the algorithm efficiency and may contain some low-\nqualityedges.Thus,weneedtoselectsomeappropriateones\nfrom each enlarged candidate set. Such a task background\nsharessimilaritieswiththeMABmodel,whichalsoneedsto\nperformselectionsfrommultiplecandidatesandlacksprior\nknowledgeforselectingthebestonesineachstep.Thereare\nalso some differences between them, i.e., the candidate set\nneeds to produce multiple candidate edges and the MAB\nmodel usually only pulls one arm per step. Therefore, we\nestablishthetaskasavariantMABmodel[36],whichpulls\nmultiplearmseachtime.Specifically,weassociateeachcity\nwithanMAB,whereeacharmcorrespondstoanedgeinits\nenlargedcandidateset,andpullingeacharmcorrespondsto\nselect the corresponding edge as a candidate edge.\nFor each arm in each MAB, we assign it an evaluation\nvalue, denoted as ğ‘€-value. Theğ‘€-values are initialized to\nbe 0 in the beginning. The larger the ğ‘€-value of an arm,\nthe more the benefit of selecting it as a candidate edge.\nOur MAB models can learn from the search process and\nadjust theğ‘€-values, using them to recommend appropriate\ncandidate edges for the local search algorithm.\n4.1.2. Methods for Pulling the Arms\nIn our method, each MAB needs to pull ğ‘ğ‘ğ‘Ÿğ‘š(5 by\ndefaultequalsto ğ¶ğ‘šğ‘ğ‘¥ofLKH)armspercallingandrecom-\nmendsğ‘ğ‘ğ‘Ÿğ‘šcorrespondingcandidateedgestoparticipateinAlgorithm 1: CallBandit(ğœ–,ğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘ğ‘Ÿğ‘š)\nInput:ğœ–-greedy parameter: ğœ–, integer for\ndetermining the method: ğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ , number\nof pulled arms: ğ‘ğ‘ğ‘Ÿğ‘š\nOutput:Candidate edges ğ¸ğ‘ğ‘ğ‘›ğ‘‘\n1switchbandtype do\n2case0doselectğ¸ğ‘ğ‘ğ‘›ğ‘‘by theğœ–-greedy method;\n3case1doselectğ¸ğ‘ğ‘ğ‘›ğ‘‘bytheğ‘€-greedymethod;\n4case2doselectğ¸ğ‘ğ‘ğ‘›ğ‘‘by theğ›¼-greedy method;\n5returnğ¸ğ‘ğ‘ğ‘›ğ‘‘;\nthelocalsearchprocess.Wedesignthreemethodsforselect-\ning the arms to be pulled, denoted as ğœ–-greedy,ğ‘€-greedy,\nandğ›¼-greedy, respectively. Their formal descriptions are as\nfollows.\nâ€¢ğœ–-greedyrandomlyexplorestheedgesintheenlarged\ncandidate set with a probability of ğœ–(0< ğœ– < 1) and\nmakesagreedyselectionpreferringedgeswithlarger\nğ‘€-values with a probability of 1 âˆ’ğœ–.\nâ€¢ğ‘€-greedyselectsğ‘ğ‘ğ‘Ÿğ‘šedges with the largest ğ‘€-\nvalues greedily among each enlarged candidate set.\nâ€¢ğ›¼-greedyselectsğ‘ğ‘ğ‘Ÿğ‘šedgeswiththelargest ğ›¼-values\ngreedily among each enlarged candidate set.\nThe above three methods are used alternatively during\nthe search process. Actually, the ğ‘€-values and ğ›¼-values\nshare similarities and differences. Both of them serve as\nmetricsoftheedges.The ğ›¼-valuesarepredeterminedbefore\nthe local search process, evaluating the quality of the edges\nwith a global perspective. In contrast, the ğ‘€-values are\ncontinuously learned and updated during the local search\nprocess. We believe that these two metrics are complemen-\ntaryinevaluatingandselectingthecandidateedges,andthe\nutilizationofthe ğ‘€-greedyand ğ›¼-greedymethodscombine\ntheir complementarity. Moreover, the ğœ–-greedy allows the\nMABreinforcementlearningmodelstotrade-offexploration\nandexploitation.Experimentalresultsalsodemonstratethat\nthe combination of the three methods can improve the ro-\nbustness of the local search algorithm.\nGiven theğ‘€-values andğ›¼-values of the edges, the pa-\nrameterğœ–,anintegerğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ fordeterminingtheselection\nof the three methods, and the number of pulled arms per\ncalling of MAB ğ‘ğ‘ğ‘Ÿğ‘š, Algorithm 1 shows a CallBandit()\nfunction that calls the MAB models to select the candidate\nedges for the local search algorithm. The set of all selected\ncandidate edges is denoted as ğ¸ğ‘ğ‘ğ‘›ğ‘‘.\n4.2. Main Process of bandLKH\nAfter establishing the MAB model and the method for\nselecting candidate edges, we summarize the main frame-\nwork of bandLKH in this subsection, which is depicted\nin Algorithm 2. In the initialization stage (lines 1-5), the\nalgorithm initializes the enlarged candidate sets, the ğ‘€-\nvalues,andsomeinformationinvolvedinthesearchprocess.\nWang et al.: Preprint submitted to Elsevier Page 4 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nDuring the local search process (lines 6-19), the algorithm\nfirst generates an initial solution ğ‘…by function ChooseIni-\ntialTour() in LKH (line 7) and then calls the MAB models\nby function CallBandit() (Algorithm 1) to select the candi-\ndate edgesğ¸ğ‘ğ‘ğ‘›ğ‘‘(line 8). The selected ğ¸ğ‘ğ‘ğ‘›ğ‘‘will be used\nto guide the LinKernighan() function, which performs the\nsearch operators introduced in Section 3.2.2 to improve ğ‘…\nto a local optimum (line 9). The ğ‘€-values of the selected\ncandidate edges will be updated according to the quality of\ntheobtainedlocaloptimalsolution(line10).Moreover,ifthe\nbest solution ğ‘…âˆ—has not been improved for ğ‘‡ğ‘¡ğ‘¦ğ‘ğ‘’trials, the\nğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ willbechanged(line18)totrytousedifferentarm\nselection methods to help the algorithm escape from local\noptima.\nFor the time complexity, the additional operations of\nbandLKHoverLKHaretheCallBanditandUpdateMfunc-\ntions. CallBandit sorts the enlarged candidate set with size\nğ¶ğ‘šğ‘ğ‘¥(7 by default) of each city, costing a time complexity\nofğ‘‚(ğ‘›ğ¶ğ‘šğ‘ğ‘¥ğ‘™ğ‘œğ‘”(ğ¶ğ‘šğ‘ğ‘¥), whereğ‘›is the number of cities.\nUpdateM traverses the selected candidate edges once, cost-\ning a time complexity of ğ‘‚(ğ‘›). For the space complexity,\nbandLKH associates an ğ‘€-value with each candidate city,\ncosting a space complexity of ğ‘‚(ğ¶ğ‘šğ‘ğ‘¥ğ‘›). Therefore, both\nthe time and space complexities are of linear order and\nacceptable for large-scale problems.\nIn summary, the proposed bandLKH algorithm uses\nthe MAB models to help select candidate edges for the\nlocal search process. The MAB models select the candidate\nedges referring to the evaluation values of the arms, i.e.,\nğ‘€-values, and can learn from the searching process to\nupdatetheğ‘€-valuesandrecommendappropriateandhigh-\nquality candidate edges. The selected candidate edges can\nbeusedforvarioussearchoperatorsinLKHencapsulatedin\nthe LinKernighan() function, including sequential and non-\nsequential moves.\n4.3. Update the ğ‘€-values with Rewards\nTo update the evaluation values, i.e., ğ‘€-values, of the\narms in our MAB models, we need to design the reward\nfunctions for evaluating the benefit of pulling the arms, i.e.,\nselectingthecorrespondingcandidateedges.Suppose ğ‘…âˆ—is\nthe best solution found during the search process and ğ‘…is\nthe solution obtained by the function LinKernighan() based\nontheselectedcandidateedgesinthecurrenttrial.Asimple\nand straightforward reward function is designed as follows.\nğ‘Ÿ(ğ‘…,ğ‘…âˆ—) =ğ¿(ğ‘…âˆ—) âˆ’ğ¿(ğ‘…). (2)\nGiven the above reward function, the function Up-\ndateM() updates the ğ‘€-value of each selected candidate\nedge (ğ‘–,ğ‘—) âˆˆğ¸ğ‘ğ‘ğ‘›ğ‘‘in an incremental manner by the fol-\nlowing equation.\nğ‘€(ğ‘–,ğ‘—) = (1 âˆ’ğœ†)â‹…ğ‘€(ğ‘–,ğ‘—) +ğœ†â‹…ğ‘Ÿ(ğ‘…,ğ‘…âˆ—),(3)\nwhere 0<ğœ†< 1is the incremental reward parameter.Algorithm 2: bandLKH\nInput:A TSP instance: ğ¼, enlarged size of\ncandidate sets: ğ¶ğ‘šğ‘ğ‘¥, maximum number of\ntrials:ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘Ÿğ‘–ğ‘ğ‘™ğ‘  , the cut-off time:\nğ‘€ğ‘ğ‘¥ğ‘‡ğ‘–ğ‘šğ‘’ , number of pulled arms: ğ‘ğ‘ğ‘Ÿğ‘š,\nmaximum no-improvement trials for change\nğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ :ğ‘‡ğ‘¡ğ‘¦ğ‘ğ‘’,ğœ–-greedy parameter: ğœ–,\nincremental reward parameter: ğœ†\nOutput:The best solution found for ğ¼:ğ‘…âˆ—\n1Initialize each enlarged candidate set containing\nğ¶ğ‘šğ‘ğ‘¥edges based on ğ›¼-values;\n2Initialize length of the best solution ğ¿(ğ‘…âˆ—)â†+âˆ;\n3Initialize the number of no-improvement trials\nğ‘¡â†0;\n4Initializeğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ â†0;\n5Initialize the ğ‘€-values to 0;\n6forğ‘–â†1 âˆ¶ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘Ÿğ‘–ğ‘ğ‘™ğ‘  do\n7ğ‘…â†ChooseInitialTour();\n8ğ¸ğ‘ğ‘ğ‘›ğ‘‘â†CallBandit(ğœ–,ğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘ğ‘Ÿğ‘š);\n9ğ‘…â†LinKernighan( ğ¼,ğ‘…,ğ¸ğ‘ğ‘ğ‘›ğ‘‘);\n10UpdateM(ğ¸ğ‘ğ‘ğ‘›ğ‘‘,ğ‘…,ğ‘…âˆ—,ğœ†);\n11ifğ¿(ğ‘…)<ğ¿(ğ‘…âˆ—)then\n12ğ‘…âˆ—â†ğ‘…;\n13ğ‘¡â†0;\n14else\n15ğ‘¡â†ğ‘¡+ 1;\n16 ifğ‘¡â‰¥ğ‘‡ğ‘¡ğ‘¦ğ‘ğ‘’then\n17 ğ‘¡â†0;\n18 ğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ â†(ğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ + 1)%3;\n19ifrunning time >ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘–ğ‘šğ‘’ thenbreak ;\n20returnğ‘…âˆ—;\n5. Experiment\nIn this section, we first make a detailed comparison\nbetween bandLKH and LKH1(version 2.0.10) to evalu-\nate the performance of our proposed new algorithm. We\nalso compare bandLKH with representative learning-based\nmethods, including the deep learning-based NeuroLKH al-\ngorithm [16] and the traditional reinforcement learning-\nbasedVSR-LKHalgorithm[15].Wefurtherpresentablation\nstudies to evaluate the efficacy of components in bandLKH\nand provide further insights.\nFinally, we apply our method to LKH-3 [17], an exten-\nsionofLKHthatcansolvemanyTSPvariants.Theresulting\nsolver is called bandLKH-3. We select two representative\nvariants of TSP: the Multiple Traveling Salesmen Problem\n(MTSP), where the cities are visited by ğ‘šsalesmen, and\nthe goal is to minimize their total traveling distance, and\nthe Capacitated Vehicle Routing Problem (CVRP), which\nregards the salesmen and cities as vehicles with capacities\nandcustomerswithdemands,andthegoalistominimizethe\ntotal traveling distance of the vehicles while ensuring that\n1http://webhotel4.ruc.dk/ keld/research/LKH/\nWang et al.: Preprint submitted to Elsevier Page 5 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nTable 1\nDetailed comparison results of bandLKH and LKH. The best results appear in bold.\nInstance BKSLKH bandLKH\nSuccess Best (%) Average (%) Trials Time (s) Success Best (%) Average (%) Trials Time (s)\ngr137 69853 10/10 69853 (0.0000) 69853 (0.0000) 1.0 0.01 9/10 69853 (0.0000) 69865.7 (0.0182) 18.9 0.01\nch150 6528 9/10 6528 (0.0000) 6528.5 (0.0077) 60.1 0.05 10/10 6528 (0.0000) 6528 (0.0000) 23.3 0.08\nkroB150 26130 2/10 26130 (0.0000) 26131.6 (0.0061) 128.4 0.24 10/10 26130 (0.0000) 26130 (0.0000) 54.1 0.21\nsi175 21407 7/10 21407 (0.0000) 21407.3 (0.0014) 105.9 6.15 9/10 21407 (0.0000) 21407.1 (0.0005) 35.3 4.95\nrat195 2323 9/10 2323 (0.0000) 2323.5 (0.0215) 55.0 0.15 10/10 2323 (0.0000) 2323 (0.0000) 14.8 0.19\ngr229 134602 2/10 134602 (0.0000) 134613.2 (0.0083) 203.1 0.20 10/10 134602 (0.0000) 134602 (0.0000) 25.9 0.14\npr299 48191 9/10 48191 (0.0000) 48194.3 (0.0068) 51.7 0.36 10/10 48191 (0.0000) 48191 (0.0000) 21.6 0.68\nlin318 42029 4/10 42029 (0.0000) 42085.4 (0.1342) 249.3 0.55 9/10 42029 (0.0000) 42040.4 (0.0271) 53.0 0.34\ngr431 171414 3/10 171414 (0.0000) 171499.2 (0.0497) 347.0 1.73 10/10 171414 (0.0000) 171414 (0.0000) 73.7 2.26\nd493 35002 2/10 35002 (0.0000) 35003.6 (0.0046) 419.3 2.62 10/10 35002 (0.0000) 35002 (0.0000) 28.2 0.98\nsi535 48450 7/10 48450 (0.0000) 48451.1 (0.0023) 311.6 21.28 9/10 48450 (0.0000) 48450.3 (0.0006) 138.9 31.98\nrat575 6773 2/10 6773 (0.0000) 6773.8 (0.0118) 526.9 2.32 6/10 6773 (0.0000) 6773.4 (0.0059) 392.5 4.93\ngr666 294358 5/10 294358 (0.0000) 294417 (0.0200) 459.8 2.41 6/10 294358 (0.0000) 294393.7 (0.0121) 372.9 10.01\npr1002 259045 8/10 259045 (0.0000) 259045.6 (0.0002) 549.0 3.13 10/10 259045 (0.0000) 259045 (0.0000) 90.7 2.83\nu1060 224094 5/10 224094 (0.0000) 224107.5 (0.0060) 663.3 84.17 10/10 224094 (0.0000) 224094 (0.0000) 44.4 22.00\nvm1084 239297 3/10 239297 (0.0000) 239372.6 (0.0316) 824.1 32.98 8/10 239297 (0.0000) 239307.4 (0.0043) 323.9 26.51\npcb1173 56892 4/10 56892 (0.0000) 56895 (0.0053) 844.0 3.92 8/10 56892 (0.0000) 56893 (0.0018) 418.4 9.79\nd1291 50801 5/10 50801 (0.0000) 50840 (0.0768) 995.4 27.44 10/10 50801 (0.0000) 50801 (0.0000) 192.2 14.74\nrl1304 252948 3/10 252948 (0.0000) 253156.4 (0.0824) 1170.0 12.48 10/10 252948 (0.0000) 252948 (0.0000) 572.1 27.38\nrl1323 270199 6/10 270199 (0.0000) 270219.6 (0.0076) 718.8 9.63 8/10 270199 (0.0000) 270204.4 (0.0020) 576.9 23.75\nnrw1379 56638 6/10 56638 (0.0000) 56640 (0.0035) 759.3 8.87 6/10 56638 (0.0000) 56639.6 (0.0028) 928.0 35.27\nfl1400 20127 0/10 20164 (0.1838) 20165.5 (0.1913) 1400.0 113.30 6/10 20127 (0.0000) 20141.8 (0.0735) 721.0 219.18\nfl1577 22249 0/10 22254 (0.0225) 22260.6 (0.0521) 1577.0 1172.10 9/10 22249 (0.0000) 22249.5 (0.0022) 614.9 1920.79\nvm1748 336556 9/10 336556 (0.0000) 336557.3 (0.0004) 1007.9 12.69 10/10 336556 (0.0000) 336556 (0.0000) 146.4 9.99\nu1817 57201 1/10 57201 (0.0000) 57251.1 (0.0876) 1817.0 74.19 1/10 57201 (0.0000) 57237.3 (0.0635) 1750.3 260.67\nrl1889 316536 0/10 316549 (0.0041) 316549.8 (0.0044) 1889.0 61.40 10/10 316536 (0.0000) 316536 (0.0000) 236.5 35.56\nd2103 80450 0/10 80471 (0.0261) 80505.7 (0.0692) 2103.0 67.07 7/10 80450 (0.0000) 80451 (0.0012) 1084.0 306.06\nu2152 64253 3/10 64253 (0.0000) 64287.7 (0.0540) 1614.0 73.81 8/10 64253 (0.0000) 64264.4 (0.0177) 793.6 135.39\npcb3038 137694 4/10 137694 (0.0000) 137701.2 (0.0052) 2078.6 69.56 5/10 137694 (0.0000) 137700.7 (0.0049) 2081.1 275.37\nfl3795 28772 4/10 28772 (0.0000) 28783.2 (0.0389) 2998.1 423.94 5/10 28772 (0.0000) 28778.5 (0.0226) 3012.3 2437.03\nfnl4461 182566 9/10 182566 (0.0000) 182566.5 (0.0003) 923.1 31.05 10/10 182566 (0.0000) 182566 (0.0000) 153.4 37.02\nrl5915 565530 1/10 565530 (0.0000) 565621.5 (0.0162) 5915.0 242.05 3/10 565530 (0.0000) 565564.4 (0.0061) 4863.8 1663.58\nrl5934 556045 0/10 556172 (0.0228) 556377.6 (0.0598) 5934.0 305.02 8/10 556045 (0.0000) 556063.2 (0.0033) 3472.1 1607.18\nxmc10150 28387 0/5 28388 (0.0035) 28388.8 (0.0063) 10000.0 832.77 0/5 28389 (0.0070) 28390.8 (0.0134) 10000.0 4279.32\nfi10639 520527 0/5 520534 (0.0013) 520562.8 (0.0069) 10000.0 844.41 0/5 520539 (0.0023) 520564.2 (0.0071) 10000.0 4636.34\nrl11849 923288 1/5 923288 (0.0000) 923360.2 (0.0078) 9257.4 947.41 1/5 923288 (0.0000) 923323.6 (0.0039) 8532.0 3633.09\nusa13509 19982859 0/5 19982874 (0.0001) 19983306.2 (0.0022) 10000.0 1111.75 0/5 19983027 (0.0008) 19983277.2 (0.0021) 10000.0 6300.91\nxvb13584 37083 1/5 37083 (0.0000) 37087.2 (0.0113) 8251.2 1053.74 0/5 37086 (0.0081) 37090.4 (0.0200) 10000.0 5740.31\nbrd14051 469385 0/5 469395 (0.0021) 469397.4 (0.0026) 10000.0 1789.55 0/5 469412 (0.0058) 469460.6 (0.0161) 10000.0 8240.87\nmo14185 427377 0/5 427381 (0.0009) 427402.6 (0.0060) 10000.0 1408.07 0/5 427380 (0.0007) 427385.8 (0.0021) 10000.0 6173.50\nxrb14233 45462 0/5 45466 (0.0088) 45468.4 (0.0141) 10000.0 1376.69 1/5 45462 (0.0000) 45465 (0.0066) 10000.0 6659.30\nho14473 177092 0/5 177161 (0.0390) 177182.6 (0.0512) 332.2 43362.26 0/5 177117 (0.0141) 177138 (0.0260) 402.8 43336.19\nd15112 1573084 0/5 1573202 (0.0075) 1573242.6 (0.0101) 10000.0 2109.11 0/5 1573288 (0.0130) 1573318.8 (0.0149) 10000.0 9560.62\nit16862 557315 0/5 557319 (0.0007) 557336 (0.0038) 10000.0 6012.14 0/5 557319 (0.0007) 557332.4 (0.0031) 8975.0 39870.58\nxia16928 52850 1/5 52850 (0.0000) 52853.2 (0.0061) 10000.0 1673.98 1/5 52850 (0.0000) 52852 (0.0038) 10000.0 9295.23\npjh17845 48092 0/5 48093 (0.0021) 48100.4 (0.0175) 10000.0 1739.08 0/5 48093 (0.0021) 48095.6 (0.0075) 10000.0 10022.94\nd18512 645238 0/5 645263 (0.0039) 645268.8 (0.0048) 10000.0 2668.68 0/5 645353 (0.0178) 645424.4 (0.0289) 10000.0 10513.63\nfrh19289 55798 0/5 55800 (0.0036) 55806.8 (0.0158) 10000.0 1836.78 0/5 55804 (0.0108) 55808.8 (0.0194) 10000.0 11312.59\nfnc19402 59287 0/5 59303 (0.0270) 59308.6 (0.0364) 10000.0 1823.40 0/5 59295 (0.0135) 59298.6 (0.0196) 10000.0 9574.85\nido21215 63517 0/5 63525 (0.0126) 63533.6 (0.0261) 10000.0 2161.70 0/5 63519 (0.0031) 63525.6 (0.0135) 10000.0 14603.81\nfma21553 66527 0/5 66529 (0.0030) 66540.4 (0.0201) 10000.0 2102.46 1/5 66527 (0.0000) 66534.8 (0.0117) 10000.0 11584.06\nvm22775 569288 0/5 569299 (0.0019) 569308.6 (0.0036) 10000.0 7171.50 0/5 569290 (0.0004) 569308.8 (0.0037) 10000.0 20219.20\nlsb22777 60977 0/5 60981 (0.0066) 60989 (0.0197) 10000.0 2625.61 0/5 60978 (0.0016) 60983.8 (0.0112) 10000.0 15632.94\nxrh24104 69294 0/5 69300 (0.0087) 69304.2 (0.0147) 10000.0 2303.96 0/5 69297 (0.0043) 69303.2 (0.0133) 10000.0 16508.96\nsw24978 855597 0/5 855599 (0.0002) 855628 (0.0036) 10000.0 2807.11 0/5 855602 (0.0006) 855611.8 (0.0017) 10000.0 17463.64\nbbz25234 69335 0/5 69343 (0.0115) 69349.8 (0.0213) 10000.0 2938.86 0/5 69340 (0.0072) 69346.2 (0.0162) 10000.0 21084.39\nirx28268 72608 0/5 72614 (0.0083) 72622 (0.0193) 10000.0 2979.10 1/5 72608 (0.0000) 72610.2 (0.0030) 10000.0 17642.29\nfyg28534 78562 0/5 78571 (0.0115) 78574.6 (0.0160) 10000.0 2941.72 0/5 78568 (0.0076) 78573.2 (0.0143) 10000.0 21597.03\nicx28698 78087 0/5 78100 (0.0166) 78106.8 (0.0254) 10000.0 3237.22 0/5 78093 (0.0077) 78104.4 (0.0223) 10000.0 22079.87\nird29514 80353 0/5 80366 (0.0162) 80374.8 (0.0271) 10000.0 3052.62 0/5 80380 (0.0336) 80392.4 (0.0490) 10000.0 24177.14\npla33810 66048945 0/5 66061689 (0.0193) 66065656.2 (0.0253) 3000.0 25030.56 0/5 66052269 (0.0050) 66062745 (0.0209) 1442.4 29411.21\npla85900 142382641 0/5 142455345 (0.0511) 142457070.8 (0.0523) 3000.0 9270.29 0/5 142404864 (0.0156) 142411899.2 (0.0205) 3000.0 25842.53\nAverage Gap (%) - - 0.0085 0.0249 - - - 0.0030 0.0107 - -\nTable 2\nSummarized comparison results of bandLKH and learning-based methods, VSR-LKH and NeuroLKH. The best results appear in\nbold.\nIndicator bandLKH VSR-LKH bandLKH NeuroLKH_R bandLKH NeuroLKH_M\nğ‘Šğ‘–ğ‘›ğ‘ğ‘’ğ‘ ğ‘¡ 2 0 8 0 5 0\nğ‘Šğ‘–ğ‘›ğ‘ğ‘£ğ‘” 13 9 22 8 13 9\nğºğ‘ğ‘ğ‘ğ‘’ğ‘ ğ‘¡ 0.0000% 0.0027% 0.0000% 0.0215% 0.0000% 0.0803%\nğºğ‘ğ‘ğ‘ğ‘£ğ‘” 0.0036% 0.0060% 0.0043% 0.0366% 0.0043% 0.0834%\neach customerâ€™s demand is satisfied and the total demand\ndoes not exceed the capacity of any vehicle. We compare\nbandLKH-3 with LKH-3 in solving MTSP and CVRP and\nevaluate the generalization capability of our method.\n5.1. Experimental Setup\nbandLKH was implemented in C Programming Lan-\nguage.TheexperimentswererunonaserverusinganAMDEPYC 7H12 CPU, running Ubuntu 18.04 Linux operation\nsystem.Wetestedthealgorithmsinallthe82symmetryTSP\ninstancesfromtheTSPLIB2benchmarkwiththenumberof\ncities ranging from 101 to 85,900, and all the 22 instances\nwith the number of cities ranging from 10,000 to 30,000\n2http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/\nWang et al.: Preprint submitted to Elsevier Page 6 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nTable 3\nSummarized comparison results of bandLKH and its variants, bandLKH-no ğœ–, bandLKH-no ğ‘€, and bandLKH-no ğ›¼. The best results\nappear in bold.\nIndicator bandLKH bandLKH-no ğœ–bandLKH bandLKH-no ğ‘€bandLKH bandLKH-no ğ›¼\nğ‘Šğ‘–ğ‘›ğ‘ğ‘’ğ‘ ğ‘¡ 0 0 0 0 2 0\nğ‘Šğ‘–ğ‘›ğ‘ğ‘£ğ‘” 12 7 6 12 28 4\nğºğ‘ğ‘ğ‘ğ‘’ğ‘ ğ‘¡ 0.0000% 0.0000% 0.0000% 0.0000% 0.0000% 0.0006%\nğºğ‘ğ‘ğ‘ğ‘£ğ‘” 0.0036% 0.0044% 0.0036% 0.0057% 0.0036% 0.0076%\nTable 4\nSummarized comparison results between bandLKH with LKH-\nğ‘ğ‘ğ‘Ÿğ‘šand LKH-ğ¶ğ‘šğ‘ğ‘¥. The best results appear in bold.\nIndicator bandLKH LKH- ğ¶ğ‘šğ‘ğ‘¥\nğ‘Šğ‘–ğ‘›ğ‘ğ‘’ğ‘ ğ‘¡ 1 0\nğ‘Šğ‘–ğ‘›ğ‘ğ‘£ğ‘” 19 12\nğºğ‘ğ‘ğ‘ğ‘’ğ‘ ğ‘¡ 0.0000% 0.0001%\nğºğ‘ğ‘ğ‘ğ‘£ğ‘” 0.0036% 0.0057%\nfrom the National TSPs3and VLSI TSPs4benchmarks. We\nalso use the 82 instances from TSPLIB with ğ‘š= 3as\nthe MTSP benchmarks. A TSP instance can be transformed\ninto an MTSP instance by regarding the first city as the\ndepot. Note that the number in the name of a TSP instance\nindicates the number of cities it contains. For CVRP, we\ntested LKH-3 and bandLKH-3 in the dataset proposed by\nUchoaetal.[37]5containing100instanceswiththenumber\nof customers ranging from 100 to 1,001.\nWe set the cut-off time ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘–ğ‘šğ‘’ and the maximum\nnumber of iterations ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘Ÿğ‘–ğ‘ğ‘™ğ‘  to be the same for the\nalgorithms.ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘Ÿğ‘–ğ‘ğ‘™ğ‘  issettothenumberofcities(default\nsettings in LKH and LKH-3) for instances with less than\n10,000 cities, 10,000 for instances with more than 10,000\ncities, and 3,000 for instances with more than 30,000 cities.\nEach TSP instance with less than 10,000 cities was run 10\ntimes by each algorithm with different random seeds. The\nrest of the instances were run 5 times by each algorithm.\nğ‘€ğ‘ğ‘¥ğ‘‡ğ‘–ğ‘šğ‘’ issettoonedayforalltheinstances.Ineachrun,\nthe algorithm will terminate and start the next run when it\nfinds the optimal solution.\nParameters related to the MAB in bandLKH and\nbandLKH-3 include the enlarged size of candidate sets:\nğ¶ğ‘šğ‘ğ‘¥, the number of pulled arms in each bandit: ğ‘ğ‘ğ‘Ÿğ‘š,\nthe maximum no-improvement trials for change ğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ :\nğ‘‡ğ‘¡ğ‘¦ğ‘ğ‘’,theğœ–-greedyparameter: ğœ–,andtheincrementalreward\nparameter:ğœ†. We adopted an automatic configurator called\nSMAC3[38]totunethembasedonsomesampledinstances,\nandtheirdefaultsettingsareasfollows: ğ¶ğ‘šğ‘ğ‘¥= 7,ğ‘ğ‘ğ‘Ÿğ‘š= 5,\nğ‘‡ğ‘¡ğ‘¦ğ‘ğ‘’=ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘Ÿğ‘–ğ‘ğ‘™ğ‘  âˆ•20by referring to VSR-LKH, ğœ–=\n0.15, andğœ†= 0.16. Other parameters are the same as those\nin LKH and LKH-3. The tuning domains of ğ¶ğ‘šğ‘ğ‘¥,ğœ–, and\n3https://www.math.uwaterloo.ca/tsp/world/countries.html\n4https://www.math.uwaterloo.ca/tsp/vlsi/index.html\n5http://www.vrp-rep.org/datasets/item/2016-0019.htmlğœ†are[6,8],[0.05,0.06,...,0.30], and [0.05,0.06,...,0.30],\nrespectively.\n5.2. Comparison of bandLKH and LKH\nThissubsectioncomparesbandLKHandLKH.Actually,\nLKH selects 5 fixed candidate edges for each city, and\nbandLKH selects ğ‘ğ‘ğ‘Ÿğ‘š= 5more appropriate candidate\nedges in a larger candidate set (with size equals ğ¶ğ‘šğ‘ğ‘¥= 7)\nfor each city using the proposed MAB model.\nThe detailed comparison results between bandLKH and\nLKHareshowninTable1.Column ğµğ¾ğ‘†indicatesthebest-\nknownsolutionsoftheinstances,andweonlypresentallthe\n62 instances in which at least one of LKH and bandLKH\ncannot obtain the ğµğ¾ğ‘†in each run. Actually, the ğµğ¾ğ‘†\nof tested instances from TSPLIB and National TSPs have\nbeen proven to be optimal. Column Successindicates the\nsuccess rate to find the ğµğ¾ğ‘†, columns BestandAverage\nindicate the best and average solutions of the algorithms,\nrespectively, with their gaps to the ğµğ¾ğ‘†placed in the\nbrackets, and columns TrialsandTimeindicate the average\ntrialsandrunningtimeofthealgorithms.Wefurtherpresent\ntheaveragegapofthebestandaveragesolutionstothe ğµğ¾ğ‘†\nat the bottom of Table 1.\nThe results show that bandLKH obtains better (resp.\nworse) results in terms of the success rate in 33 (resp. 1)\ninstances and better (resp. worse) results in terms of the\naverage solution in 52 (resp. 10) instances. The average gap\nof the best (resp. average) solutions obtained by bandLKH\nto theğµğ¾ğ‘†is about 65% (resp. 57) smaller than that\nof LKH. We can also observe that bandLKH significantly\noutperforms LKH in solving instances with various scales.\nThe results indicate that bandLKH has significantly better\nperformance and robustness than LKH.\n5.3. Comparison with Learning-based Methods\nTo further show the performance and advantage of our\nlearning method, we compare bandLKH with the state-of-\nthe-art learning-based methods for TSP, including the Neu-\nroLKH algorithm [16], which combines deep learning and\nLKH, and the VSR-LKH algorithm [15], which combines\ntraditional reinforcement learning with LKH. We compare\nbandLKH with two versions of NeuroLKH, NeuroLKH_R\nand NeuroLKH_M, which were trained in instances with\nuniformly distributed nodes and a mixture of instances\nwith uniformly distributed nodes, clustered nodes, half uni-\nform and half clustered nodes, respectively. We compare\nbandLKH with VSR-LKH in 75 TSPLIB instances whose\nWang et al.: Preprint submitted to Elsevier Page 7 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nTable 5\nDetailed comparison of LKH3 and bandLKH-3 on CVRP. The best results appear in bold.\nLKH-3 bandLKH-3\nInstance Best Average Trials Time(s) Best Average Trials Time(s)\nX-n101-k25 27653 27717.4 10000.0 56.48 27591 27625 7393.0 19.872\nX-n106-k14 26389 26482.2 10000.0 50.67 26386 26388.2 10000.0 61.72\nX-n110-k13 14971 14971 1271.0 0.37 14971 14971 2048.0 0.698\nX-n115-k10 12747 12754 5159.0 1.76 12747 12747 314.0 0.069\nX-n120-k6 13332 13351.5 6011.0 3.03 13340 13374.4 10000.0 12.692\nX-n125-k30 55736 55880.4 10000.0 161.35 55675 55812.2 10000.0 167.218\nX-n129-k18 28958 29034.4 10000.0 38.26 28957 29049.4 10000.0 47.892\nX-n134-k13 10933 10985.2 10000.0 39.71 10918 10964.4 10000.0 50.12\nX-n139-k10 13590 13590 1167.0 0.33 13612 13641 10000.0 16.549\nX-n143-k7 15726 15774.4 10000.0 24.08 15726 15789.6 10000.0 29.478\nX-n148-k46 43448 43448 5442.0 5.01 43594 43706.8 10000.0 50.921\nX-n153-k22 21254 21290.6 10000.0 71.11 21247 21275.4 10000.0 87.463\nX-n157-k13 16876 16885 5339.0 3.22 16876 16876 2229.0 1.007\nX-n162-k11 14138 14196.75 8457.2 8.98 14153 14167.4 10000.0 15.617\nX-n167-k10 20637 20752 10000.0 30.91 20610 20742.4 10000.0 34.993\nX-n172-k51 45733 45830.2 10000.0 58.51 45637 45806.2 10000.0 65.726\nX-n176-k26 48076 48217.8 10000.0 157.76 47895 48041.4 10000.0 186.436\nX-n181-k23 25572 25628 10000.0 18.02 25576 25626.4 10000.0 24.256\nX-n186-k15 24279 24304 10000.0 52.09 24212 24394.2 10000.0 55.446\nX-n190-k8 17041 17197.4 10000.0 40.08 17031 17173.6 10000.0 47.873\nX-n195-k51 44322 44432 10000.0 51.65 44480 44527.4 10000.0 69.822\nX-n200-k36 58882 58934.4 10000.0 155.41 58819 58901.4 10000.0 214.636\nX-n204-k19 19699 19746.4 10000.0 22.49 19610 19696.4 10000.0 28.873\nX-n209-k16 30855 31031.8 10000.0 44.07 31043 31117 10000.0 50.978\nX-n214-k11 11138 11252.2 10000.0 107.32 11089 11189.2 10000.0 116.901\nX-n219-k73 117613 117675.2 10000.0 45.03 117613 117685.4 10000.0 1142.35\nX-n223-k34 40704 40804.6 10000.0 59.50 40688 40799.8 10000.0 71.578\nX-n228-k23 25782 25906.6 10000.0 69.01 25806 25869.8 10000.0 73.489\nX-n233-k16 19365 19465.2 10000.0 16.56 19313 19411.4 10000.0 22.386\nX-n237-k14 27128 27266.8 10000.0 29.61 27050 27165.2 10000.0 36.486\nX-n242-k48 83121 83468.8 10000.0 91.32 83197 83358 10000.0 107.912\nX-n247-k47 37353 37487.8 10000.0 114.37 37290 37337.8 10000.0 155.195\nX-n251-k28 38914 39040.4 10000.0 52.43 38812 39008 10000.0 67.16\nX-n256-k16 19062 19207.4 10000.0 70.77 19000 19213.2 10000.0 78.19\nX-n261-k13 26808 27075.2 10000.0 63.92 26948 27088.6 10000.0 89.908\nX-n266-k58 75795 76074.6 10000.0 160.84 75948 76111 10000.0 194.644\nX-n270-k35 35504 35566.8 10000.0 62.32 35506 35702.8 10000.0 75.149\nX-n275-k28 21347 21418.4 10000.0 22.63 21347 21426 10000.0 26.471\nX-n280-k17 33835 33921.6 10000.0 102.88 33725 33878 10000.0 130.435\nX-n284-k15 20348 20640 10000.0 36.72 20401 20514.6 10000.0 38.847\nX-n289-k60 96038 96238.8 10000.0 255.37 95983 96199.6 10000.0 298.468\nX-n294-k50 47473 47637 10000.0 74.52 47508 47654.8 10000.0 97.423\nX-n298-k31 34522 34776.6 10000.0 54.44 34431 34581.6 10000.0 67.207\nX-n303-k21 21919 22008.2 10000.0 36.47 21906 22027.4 10000.0 40.758\nX-n308-k13 26208 26266.6 10000.0 63.42 26022 26231 10000.0 64.52\nX-n313-k71 95087 95197.2 10000.0 250.89 94880 94950.4 10000.0 294.031\nnumber of cities ranges from 101 to 10,000 and compare\nbandLKHwithNeuroLKHin60TSPLIBinstancesreported\ninitspaper.ThesummarizedresultsareallshowninTable2.\nAs shown in Table 2, bandLKH obtains better results\nthan VSR-LKH in 2 (resp. 13) instances in terms of the\nbest (resp. average) solutions and worse results than VSR-\nLKH in 0 (resp. 9) instances in terms of the best (resp.\naverage) solutions. Moreover, bandLKH obtains better re-\nsults than NeuroLKH_R in 8 (resp. 21) instances in terms\nof the best (resp. average) solutions and worse results than\nNeuroLKH_R in 1 (resp. 8) instances in terms of the best\n(resp. average) solutions, and bandLKH obtains better re-\nsults than NeuroLKH_M in 5 (resp. 13) instances in terms\nof the best (resp. average) solutions and worse results thanNeuroLKH_M in 1 (resp. 9) instances in terms of the best\n(resp. average) solutions.\nThe results in Table 2 indicate that bandLKH has a\nsuperiorityoverthestate-of-the-artlearning-basedmethods,\nVSR-LKH and NeuroLKH. Note that NeuroLKH uses deep\nlearningmethodstohelpLKHselectcandidateedgesbefore\nlocal search, and VSR-LKH uses traditional reinforcement\nlearning to adjust the order of the candidate edges during\nthesearch.Therefore,neitherofthemchangesthecandidate\nedges of each city. The proposed bandLKH algorithm can\ndynamically suggest candidate edges from enlarged candi-\ndate sets, providing more flexibility for the algorithm and\nWang et al.: Preprint submitted to Elsevier Page 8 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nTable 6\nDetailed comparison of LKH3 and bandLKH-3 on CVRP (continued). The best results appear in bold.\nLKH-3 bandLKH-3\nInstance Best Average Trials Time(s) Best Average Trials Time(s)\nX-n317-k53 78389 78608.6 10000.0 78.26 78458 78679.6 10000.0 106.873\nX-n322-k28 30228 30369.4 10000.0 72.03 30233 30263.6 10000.0 83.37\nX-n327-k20 27887 28015.8 10000.0 58.75 28027 28078.8 10000.0 73.938\nX-n331-k15 31488 31565 10000.0 30.20 31393 31608.8 10000.0 40.726\nX-n336-k84 140006 140344.8 10000.0 231.94 140023 140283.4 10000.0 282.161\nX-n344-k43 42502 42682.6 10000.0 78.53 42551 42720.2 10000.0 98.49\nX-n351-k40 26261 26333.4 10000.0 102.05 26236 26308 10000.0 128.196\nX-n359-k29 52210 52284.8 10000.0 106.94 52061 52329.8 10000.0 136.523\nX-n367-k17 23163 23290 10000.0 48.84 23113 23240.4 10000.0 60.611\nX-n376-k94 147877 147982.2 10000.0 77.43 147840 147953.2 10000.0 93.745\nX-n384-k52 66514 66668 10000.0 136.75 66656 66833.2 10000.0 166.046\nX-n393-k38 38633 38816 10000.0 76.18 38656 38772 10000.0 95.672\nX-n401-k29 66619 66781.6 10000.0 241.04 66581 66720.4 10000.0 281.493\nX-n411-k19 20083 20165.4 10000.0 76.96 19883 19950.8 10000.0 86.724\nX-n429-k61 66136 66427.8 10000.0 108.46 66257 66419 10000.0 145.347\nX-n439-k37 36656 36755.6 10000.0 21.44 36554 36642.4 10000.0 27.291\nX-n449-k29 56523 56680.6 10000.0 318.24 56550 56697.8 10000.0 364.509\nX-n459-k26 24559 24729.8 10000.0 108.59 24507 24681.8 10000.0 126.728\nX-n469-k138 223805 224058.6 10000.0 419.96 223683 223783 10000.0 861.448\nX-n480-k70 90205 90413 10000.0 133.73 90086 90233.4 10000.0 154.667\nX-n491-k59 67539 67781.2 10000.0 304.39 67598 67780.8 10000.0 376.552\nX-n502-k39 69348 69423.4 10000.0 38.80 69417 69463 10000.0 46.82\nX-n513-k21 24589 24674.4 10000.0 30.34 24532 24623.6 10000.0 34.59\nX-n536-k96 96180 96890.8 10000.0 800.66 96131 96375.2 10000.0 935.67\nX-n548-k50 87203 87308.8 10000.0 85.52 87046 87239.6 10000.0 110.104\nX-n561-k42 43338 43452.8 10000.0 55.41 43447 43492.4 10000.0 69.445\nX-n573-k30 51131 51234.8 10000.0 159.77 51096 51279.6 10000.0 189.324\nX-n599-k92 110043 110329.2 10000.0 434.99 109920 110276.4 10000.0 549.89\nX-n613-k62 60628 60823 10000.0 165.80 60733 60843 10000.0 212.619\nX-n627-k43 62800 63375.8 10000.0 273.62 63259 63506.4 10000.0 365.921\nX-n641-k35 64933 65068.2 10000.0 181.45 64703 64894.6 10000.0 237.72\nX-n655-k131 107094 107185.6 10000.0 70.09 107027 107080.6 10000.0 94.736\nX-n670-k126 147163 147671.4 10000.0 559.93 147398 147601.8 10000.0 758.066\nX-n685-k75 69575 69776.4 10000.0 250.66 69487 69682.4 10000.0 332.686\nX-n701-k44 83208 83449.6 10000.0 238.43 82975 83313 10000.0 267.65\nX-n716-k35 44340 44602.6 10000.0 273.29 44163 44405.8 10000.0 311.628\nX-n733-k159 137636 137904.6 10000.0 137.73 137339 137707.8 10000.0 211.729\nX-n749-k98 78899 79072 10000.0 463.61 78680 78984.8 10000.0 625.813\nX-n766-k71 115947 116142.2 10000.0 464.50 116190 116273.2 10000.0 674.712\nX-n783-k48 73737 74037.6 10000.0 327.30 73964 74081.4 10000.0 445.129\nX-n801-k40 73955 74128.6 10000.0 124.16 74068 74175.2 10000.0 172.678\nX-n819-k171 159950 160368 10000.0 622.68 159608 160135.6 10000.0 947.267\nX-n837-k142 195939 196219 10000.0 361.34 195706 196116.6 10000.0 477.691\nX-n856-k95 89713 89815 10000.0 62.60 89601 89700.4 10000.0 98.436\nX-n876-k59 100566 100755.8 10000.0 473.16 100710 100855.6 10000.0 658.698\nX-n895-k37 56535 56829.4 10000.0 662.29 56468 56981.4 10000.0 1029.72\nX-n916-k207 331508 332316.4 10000.0 515.08 331326 331886.6 10000.0 889.181\nX-n936-k151 134611 135110.2 10000.0 417.54 134379 134698.2 10000.0 649.151\nX-n957-k87 86226 86460.2 10000.0 94.54 86294 86453.8 10000.0 154.913\nX-n979-k58 120134 121165.8 10000.0 1051.82 121083 121713.2 10000.0 1506.112\nX-n1001-k43 74275 74479.4 10000.0 250.94 74204 74491.6 10000.0 362.494\nleading the algorithm to escape from local optima effec-\ntively. Thus, our learning method shows better performance\nthan existing ones for TSP.\n5.4. Ablation Study\nWe perform two groups of ablation studies to evaluate\nthe effect of components in our method. The first groupfocuses on the arm selection strategies by comparing ban-\ndLKH with its three variants, bandLKH-no ğœ–, bandLKH-\nnoğ‘€, and bandLKH-no ğ›¼, which remove the ğœ–-greedy,ğ‘€-\ngreedy, and ğ›¼-greedy strategies from bandLKH, respec-\ntively.ThesecondgroupfocusesontheMABmodelbycom-\nparing bandLKH with a variant algorithm of LKH, LKH-\nğ¶ğ‘šğ‘ğ‘¥, which sets the maximum capacity of each candidate\ntoğ¶ğ‘šğ‘ğ‘¥= 7and regards all the edges of each candidate\nset as candidate edges. The ablation studies are performed\nWang et al.: Preprint submitted to Elsevier Page 9 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nTable 7\nDetailed comparison of LKH3 and bandLKH-3 on MTSP. The best results appear in bold.\nInstanceLKH3 bandLKH-3InstanceLKH3 bandLKH-3\nBest Average Trials Time (s) Best Average Trials Time (s) Best Average Trials Time (s) Best Average Trials Time (s)\neil101 646 646 128.0 0.00 646 646 114.0 0.00 u574 37012 37113 1000.0 0.09 37030 37168 1000.0 0.11\nlin105 14741 14741 1.0 0.00 14741 14741 1.0 0.00 rat575 6821 6850.6 1000.0 0.09 6832 6850.6 1000.0 0.11\npr107 44869 44869 1.0 0.00 44869 44869 1.0 0.00 p654 36890 37413.6 975.2 0.13 36890 36897.67 800.3 0.10\ngr120 7196 7196 133.0 0.00 7196 7196 465.0 0.01 d657 54422 54697.8 1000.0 0.11 54396 54521.4 1000.0 0.13\npr124 59979 59979 77.0 0.00 59979 59979 53.0 0.00 gr666 300910 301704.8 1000.0 0.12 301747 302599.4 1000.0 0.14\nbier127 119163 119163 87.0 0.00 119163 119163 45.0 0.00 u724 42599 42788.8 1000.0 0.12 42719 42784.8 1000.0 0.14\nch130 6296 6296 193.0 0.01 6296 6296 228.0 0.01 rat783 8902 8916.2 1000.0 0.13 8873 8906 1000.0 0.16\npr136 98629 98740 1000.0 0.02 98629 98629 628.0 0.01 dsj1000 18780343 18840808.2 1000.0 0.22 18809451 18830484.2 1000.0 0.29\ngr137 73410 73410 33.0 0.00 73410 73410 1.0 0.00 pr1002 264134 265246.4 1000.0 0.18 265713 266412 1000.0 0.22\npr144 59444 59444 19.0 0.00 59444 59444 19.0 0.00 si1032 93045 93101.2 1000.0 0.19 92959 93025 1000.0 0.23\nch150 6571 6589.67 816.3 0.02 6571 6571 371.0 0.01 u1060 225648 226778.4 1000.0 0.22 225759 226196.4 1000.0 0.28\nkroA150 26943 26943 1.0 0.00 26943 26943 11.0 0.00 vm1084 241570 242288.2 1000.0 0.21 242063 242842 1000.0 0.27\nkroB150 26476 26476 647.0 0.01 26476 26476 937.0 0.01 pcb1173 57880 57942 1000.0 0.21 57660 57861.4 1000.0 0.28\npr152 75893 75893 75.0 0.01 75893 75893 308.0 0.01 d1291 56320 56390.6 1000.0 0.24 56541 56819.4 1000.0 0.31\nu159 43846 43846 12.0 0.00 43846 43846 1.0 0.00 rl1304 257894 262147 1000.0 0.26 254936 255536.4 1000.0 0.34\nsi175 21717 21725.4 834.2 0.05 21717 21723.5 570.5 0.02 rl1323 274672 278159.6 1000.0 0.26 273005 274332.8 1000.0 0.34\nbrg180 1980 1980 90.0 0.00 1980 1980 99.0 0.01 nrw1379 57099 57207.4 1000.0 0.29 57001 57165.2 1000.0 0.41\nrat195 2381 2385.33 1000.0 0.02 2381 2385.8 1000.0 0.05 fl1400 21294 21515.4 1000.0 0.41 21094 21119.6 1000.0 0.58\nd198 20351 20351 282.0 0.01 20351 20351.5 582.5 0.02 u1432 154056 154629.2 1000.0 0.32 154319 154480 1000.0 0.41\nkroA200 29538 29547.33 891.7 0.02 29552 29552 1000.0 0.05 fl1577 22574 23266.8 1000.0 0.34 22603 22943 1000.0 0.43\nkroB200 29767 29767 56.0 0.01 29767 29788.75 957.0 0.04 d1655 68582 68937.4 1000.0 0.39 68826 69305.2 1000.0 0.53\ngr202 45838 45851.5 898.0 0.02 45838 45851.5 867.5 0.02 vm1748 343521 344526.4 1000.0 0.46 341308 342488 1000.0 0.64\nts225 128643 128643 115.0 0.01 128643 128643 121.0 0.01 u1817 58222 58310 1000.0 0.44 58120 58307 1000.0 0.55\ntsp225 3988 4009.67 716.7 0.03 3988 3988 703.0 0.01 rl1889 324006 324944.2 1000.0 0.50 320878 325690.8 1000.0 0.68\ngr229 137521 137935 1000.0 0.06 137357 137780 1000.0 0.07 d2103 85852 86378.6 1000.0 0.49 85786 86333.6 1000.0 0.60\ngil262 2447 2453.8 1000.0 0.04 2447 2450 1000.0 0.06 u2152 65025 65179.2 1000.0 0.61 65410 65660 1000.0 0.82\npr264 49947 50010.4 1000.0 0.04 49704 49738 906.5 0.02 u2319 235352 235563.8 1000.0 0.72 235779 235879.2 1000.0 0.90\na280 2645 2645 417.0 0.01 2645 2656.5 581.0 0.02 pr2392 384311 386713 1000.0 0.69 383045 384996.6 1000.0 0.88\npr299 48821 49071.8 1000.0 0.06 48889 49000.6 1000.0 0.07 pcb3038 140077 140308.2 1000.0 1.13 140125 140322.6 1000.0 1.41\nlin318 42391 42478 761.0 0.03 42412 42548.8 1000.0 0.07 fl3795 33249 33496 1000.0 1.62 32305 32902.4 1000.0 2.28\nlinhp318 41711 41768.2 1000.0 0.05 41748 41849 1000.0 0.07 fnl4461 185381 186091.4 1000.0 2.66 184933 185112.6 1000.0 4.09\nrd400 15355 15391.6 1000.0 0.07 15366 15395.2 1000.0 0.08 rl5915 599265 601361 1000.0 4.11 587629 590227.6 1000.0 7.20\nfl417 11941 12065.33 715.3 0.05 11941 11941.67 859.3 0.08 rl5934 593816 597851.4 1000.0 4.12 571066 586723.2 1000.0 5.81\ngr431 177596 177854.2 1000.0 0.08 177336 177643 1000.0 0.10 pla7397 24404268 24607606.6 1000.0 6.64 23928458 23991798.4 1000.0 11.33\npr439 108126 109305.2 1000.0 0.07 108126 108989.2 1000.0 0.09 rl11849 998816 1007830.4 10000.0 18.12 940468 942182 10000.0 50.34\npcb442 51071 51137 1000.0 0.07 51094 51318.4 1000.0 0.08 usa13509 20785341 21020059 10000.0 24.69 20252999 20329103.6 10000.0 66.72\nd493 42785 42876.6 1000.0 0.10 42753 42790 1000.0 0.11 brd14051 478611 483402.6 10000.0 27.83 474936 475305.2 10000.0 78.24\natt532 28310 28354 1000.0 0.10 28323 28340.2 1000.0 0.11 d15112 1604194 1604374.8 10000.0 32.08 1593905 1594424.8 10000.0 111.20\nali535 203472 205287 1000.0 0.11 203044 204406.8 1000.0 0.14 d18512 658656 659308 10000.0 49.86 654037 654150.8 10000.0 116.81\nsi535 48914 48966 1000.0 0.10 48907 48916.2 1000.0 0.13 pla33810 70686837 70769236.6 3000.0 177.45 68567400 68808980.6 3000.0 391.44\npa561 2817 2819.8 1000.0 0.12 2806 2812.6 1000.0 0.13 pla85900 166383078 166720326.8 3000.0 2042.30 157305820 158179771.8 3000.0 2769.29\nbasedonallthe75TSPLIBinstanceswhosenumberofcities\nranges from 101 to 10,000.\n5.4.1. Ablation Study on the Arm Selection Strategy\nDue to the limited space, we present summarized com-\nparisonresultsofbandLKHanditsvariants,bandLKH-no ğœ–,\nbandLKH-no ğ‘€,andbandLKH-no ğ›¼,inTable3,whererows\nğ‘Šğ‘–ğ‘›ğ‘ğ‘’ğ‘ ğ‘¡andğ‘Šğ‘–ğ‘›ğ‘ğ‘£ğ‘”indicate the number of instances in\nwhich the algorithm obtains better results of the best and\naveragesolutioninmultiplerunsthanitscompetitor,respec-\ntively, and rows ğºğ‘ğ‘ğ‘ğ‘’ğ‘ ğ‘¡andğºğ‘ğ‘ğ‘ğ‘£ğ‘”indicate the average\nvalues of the gap of the best and average solutions to the\noptimal solutions upon all the 75 instances, respectively.\nThe detailed results are referred to in the Appendix. The\nresults show that bandLKH generally outperforms the three\nvariants, indicating that our selected three arm selection\nstrategies are effective and complementary, and bandLKH\ncombines their complementarity to improve the robustness.\n5.4.2. Ablation Study on the MAB Model\nThe summarized comparison results between bandLKH\nwith LKH-ğ¶ğ‘šğ‘ğ‘¥are shown in Table 4. The results show\nthat bandLKH exhibits better performance and robustness\nthan LKH-ğ¶ğ‘šğ‘ğ‘¥in terms of the best and average solutions,\nindicatingthatdirectlyenlargingthecandidateedgesisalso\nnot a good choice since there might be some low-quality\nedges contained, and our MAB model can learn from the\nsearchprocessandsmartlyselectcandidateedgesandignore\nlow-qualityedgesintheenlargedcandidatesets,makingour\nbandLKH significantly outperform the LKH algorithm and\nalso show higher robustness than the LKH- ğ¶ğ‘šğ‘ğ‘¥algorithm\nwithout a smart filter.5.5. Generalization Evaluation on MTSP and\nCVRP\nFinally, we compare bandLKH-3 with LKH-3 in CVRP\nand MTSP and full results are presented in Table 5, Table 6\nand Table 7 respectively. As shown in full results corre-\nsponding to CVRP, bandLKH-3 shows better performance\nthan LKH-3 in most instances containing X-n101-k25, X-\nn289-k60, X-n480-k70 and X-n936-k151 .... In MTSP,\nbandLKH-3 also performs better than LKH-3 in medium\nand hard instances, such as ali535, rl1304, d2103, rl11849\nand pla85900, which shows that bandLKH-3 is suitable\nfor different scale of the problem. As time goes by, our\nproposed method could learn more beneficial information\nfrom passing trials so that guide algorithm to explore more\nsignificant search space.\nGenerally speaking, the results show that among all the\n82testedMTSPinstances,bandLKH-3obtainsbetterresults\nthan LKH-3 in 33 (resp. 47) instances in terms of the best\n(resp.average)solutionsandworseresultsthanLKH-3in21\n(resp.19)instancesintermsofthebest(resp.average)solu-\ntions.Amongallthe100testedCVRPinstances,bandLKH-\n3obtainsbetterresultsthanLKH-3in56(resp.61)instances\nin terms of the best (resp. average) solutions and worse\nresults than LKH-3 in 35 (resp. 35) instances in terms of\nthebest(resp.average)solutions.Theresultsalsoshowthat\nbandLKH-3 exhibits excellent performance in MTSP and\nCVRPinstancesacrossvariousscales.bandLKH-3exhibits\na general improvement over LKH-3 in MTSP and CVRP,\nandtheresultsindicatetheexcellentgeneralizationcapabil-\nity of our MAB method.\nWang et al.: Preprint submitted to Elsevier Page 10 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\n6. Conclusion\nSelectingappropriatecandidateedgesiscrucialforsolv-\ning various routing problems, which decides the new edges\nthat can be used to adjust solutions and explore the solution\nspace.Largercandidatesetsindicatewidersearchspaceand\nlower efficiency at the same time. Balancing the search ac-\ncuracyandefficiencyisthemagicofheuristicmethods.The\nLKHalgorithmachievesthisbytuningthecandidatesettoa\nreasonablesize.Inthiswork,weproposeanalternativemay,\ni.e., modeling the selection of candidate edges as pulling\narms in multi-armed bandits, providing opportunities for\nmore potential edges to be considered as candidate edges\nandlearningfromthesearchingprocesstoselectappropriate\ncandidate edges. Extensive comparisons, ablation studies,\nandevaluationsongeneralizationcapabilitydemonstratethe\neffectiveness of our proposed algorithm.\nThough multi-armed bandit is not a new technology,\nidentifying the limitations of LKH and combining the ban-\ndit model with the problem context to improve the local\nsearch algorithm is indeed of significant research value. In\nthe future, we will continue to refine bandLKH, such as\nadaptivelychangingthesizeofthecandidatesetstoenhance\nthe performance and robustness for problems in various\nscales. Also, our method has the potential to be extended\nto other routing problems, such as various variants of TSP\nand vehicle routing problems, that also need to select high-\nquality candidate edges.\nAcknowledgments\nThis work is supported by National Natural Science\nFoundation of China (U22B2017) and Microsoft Research\nAsia (100338928).\nReferences\n[1] MohammadRezaNazari,AfshinOroojlooy,LawrenceV.Snyder,and\nMartin TakÃ¡c. Reinforcement Learning for Solving the Vehicle\nRouting Problem. In Proceedings of the 31st Annual Conference on\nNeural Information Processing Systems , pages 9861â€“9871, 2018.\n[2] Zhouxing Su, Shihao Huang, Chungen Li, and Zhipeng LÃ¼. A\nTwo-Stage Matheuristic Algorithm for Classical Inventory Routing\nProblem. In Proceedings of the 29th International Joint Conference\non Artificial Intelligence , pages 3430â€“3436, 2020.\n[3] Yuan Jiang, Yaoxin Wu, Zhiguang Cao, and Jie Zhang. Learning to\nSolveRoutingProblemsviaDistributionallyRobustOptimization. In\nProceedings of the 36th AAAI Conference on Artificial Intelligence,\nthe 34th Conference on Innovative Applications of Artificial Intelli-\ngence,andthe12thSymposiumonEducationalAdvancesinArtificial\nIntelligence , pages 9786â€“9794, 2022.\n[4] Jingyang Zhao and Mingyu Xiao. The Linear Distance Traveling\nTournament Problem Allows an EPTAS. In Proceedings of the\n37thAAAIConferenceonArtificialIntelligence,the35thConference\non Innovative Applications of Artificial Intelligence, and the 13th\nSymposium on Educational Advances in Artificial Intelligenc , pages\n12155â€“12162, 2023.\n[5] Changhyun Kwon Sasan Mahmoudinazlou. A hybrid genetic algo-\nrithm for the minâ€“max multiple traveling salesman problem. Com-\nputers & Operations Research , 162:106455, 2024.\n[6] Qinghua Wu Yongliang Lu, Una Benlic. A population algorithm\nbased on randomized tabu thresholding for the multi-commoditypickup-and-delivery traveling salesman problem. Computers & Op-\nerations Research , 101:285â€“297, 2019.\n[7] Angelo Sifaleras Panagiotis Karakostas. The pollution traveling\nsalesmanproblemwithrefueling. Computers&OperationsResearch ,\n167:106661, 2024.\n[8] Gilbert Laporte David Canca, Eva Barrena. Arrival and service\ntime dependencies in the single-and multi-visit selective traveling\nsalesman problem. Computers & Operations Research , 166:106632,\n2024.\n[9] Yuichi Nagata and Shigenobu Kobayashi. A Powerful Genetic Al-\ngorithmUsingEdgeAssemblyCrossoverfortheTravelingSalesman\nProblem. INFORMS Journal on Computing , 25(2):346â€“363, 2013.\n[10] Xueshi Dong, Liwen Ma, Xin Zhao, Yongchang Shan, Jie Wang,\nand Zhenghao Xu. Hybrid genetic algorithm with wiener process\nfor multi-scale colored balanced traveling salesman problem. Expert\nSystems with Applications , 262, 2025.\n[11] Pablo GutiÃ©rrez-Aguirre and Carlos Contreras-Bolton. A multioper-\nator genetic algorithm for the traveling salesman problem with job-\ntimes.Expert Systems with Applications , 240, 2024.\n[12] Keld Helsgaun. An Effective Implementation of the Lin-Kernighan\nTraveling Salesman Heuristic. European Journal of Operational\nResearch, 126(1):106â€“130, 2000.\n[13] Shen Lin and Brian W. Kernighan. An Effective Heuristic Algo-\nrithm for the Traveling-Salesman Problem. Operations Research ,\n21(2):498â€“516, 1973.\n[14] Michael Held and Richard M. Karp. The Traveling-Salesman\nProblem and Minimum Spanning Trees. Operations Research ,\n18(6):1138â€“1162, 1970.\n[15] Jiongzhi Zheng, Kun He, Jianrong Zhou, Yan Jin, and Chu-Min Li.\nCombining Reinforcement Learning with Lin-Kernighan-Helsgaun\nAlgorithmfortheTravelingSalesmanProblem. In Proceedingsofthe\n35th AAAI conference on artificial intelligence, the 33rd Conference\non Innovative Applications of Artificial Intelligence, and the 11th\nSymposiumonEducationalAdvancesinArtificialIntelligence ,pages\n12445â€“12452, 2021.\n[16] Liang Xin, Wen Song, Zhiguang Cao, and Jie Zhang. NeuroLKH:\nCombining Deep Learning Model with Lin-Kernighan-Helsgaun\nHeuristic for Solving the Traveling Salesman Problem. In Proceed-\ningsofthe34thAdvancesinNeuralInformationProcessingSystems ,\npages 7472â€“7483, 2021.\n[17] Keld Helsgaun. An Extension of the Lin-Kernighan-Helsgaun TSP\nSolverforConstrainedTravelingSalesmanandVehicleRoutingProb-\nlems. Technical report, Roskilde University, 2017.\n[18] Yan Jin, Yuandong Ding, Xuanhao Pan, Kun He, Li Zhao, Tao\nQin, Lei Song, and Jiang Bian. Pointerformer: Deep Reinforced\nMulti-Pointer Transformer for the Traveling Salesman Problem. In\nProceedings of the 37th AAAI Conference on Artificial Intelligence,\nthe 35th Conference on Innovative Applications of Artificial Intelli-\ngence,andthe13thSymposiumonEducationalAdvancesinArtificial\nIntelligence , pages 8132â€“8140, 2023.\n[19] Xuanhao Pan, Yan Jin, Yuandong Ding, Mingxiao Feng, Li Zhao,\nLei Song, and Jiang Bian. Hierarchically Solving the Large-scale\nTravellingSalesmanProblem. In Proceedingsofthe37thAAAICon-\nference on Artificial Intelligence, the 35th Conference on Innovative\nApplications of Artificial Intelligence, and the 13th Symposium on\nEducational Advances in Artificial Intelligence , pages 9345â€“9353,\n2023.\n[20] Paulo R. de O. da Costa, Jason Rhuggenaath, Yingqian Zhang, and\nAlp Akcay. Learning 2-opt Heuristics for the Traveling Salesman\nProblem via Deep Reinforcement Learning. In Proceedings of the\n12th Asian Conference on Machine Learning , volume 129, pages\n465â€“480, 2020.\n[21] Jingyan Sui, Shizhe Ding, Ruizhi Liu, Liming Xu, and Dongbo\nBu. Learning 3-opt Heuristics for Traveling Salesman Problem via\nDeep Reinforcement Learning. In Proceedings of the 13th Asian\nConference on Machine Learning , volume 157, pages 1301â€“1316,\n2021.\nWang et al.: Preprint submitted to Elsevier Page 11 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\n[22] YiningMa,ZhiguangCao,andYeowMengChee. Learningtosearch\nfeasible and infeasible regions of routing problems with flexible\nneural k-opt. Advances in Neural Information Processing Systems ,\n36, 2024.\n[23] Aigerim Bogyrbayeva, Taehyun Yoon, Hanbum Ko, Sungbin Lim,\nHyokun Yun, and Changhyun Kwon. A Deep Reinforcement Learn-\ning Approach for Solving the Traveling-Salesman Problem with\nDrone.Transportation Research Part C: Emerging Technologies ,\n148:103981, 2023.\n[24] Xavier Bresson and Thomas Laurent. The Transformer Network for\nthe Traveling-Salesman Problem. arXiv preprint arXiv:2103.03012 ,\n2021.\n[25] Syu-Ning Johnn, Victor-Alexandru Darvariu, Julia Handl, and JÃ¶rg\nKalcsics. A graph reinforcement learning framework for neural\nadaptive large neighbourhood search. Computers & Operations\nResearch, 172, 2024.\n[26] Elias B. Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and\nLe Song. Learning Combinatorial Optimization Algorithms over\nGraphs. In Proceedings of the 30th Annual Conference on Neural\nInformation Processing Systems , pages 6348â€“6358, 2017.\n[27] Yeong-Dae Kwon, Jinho Choo, Byoungjip Kim, Iljoo Yoon,\nYoungjune Gwon, and Seungjai Min. POMO: Policy Otimization\nwithMultipleOptimaforReinforcementLearning. In Proceedingsof\nthe 33rd Advances in Neural Information Processing Systems , pages\n33: 21188â€“21198, 2020.\n[28] Haoran Ye, Jiarui Wang, Helan Liang, Zhiguang Cao, Yong Li, and\nFanzhangLi. GLOP:LearningGlobalPartitionandLocalConstruc-\ntion for Solving Large-scale Routing Problems in Real-time. arXiv\npreprint arXiv , 2312:08224, 2023.\n[29] Nina Mazyavkina, Sergey Sviridov, Sergei Ivanov, and Evgeny Bur-\nnaev. Reinforcement Learning for Combinatorial Optimization: A\nSurvey.Computers & Operations Research , 134:105400, 2021.\n[30] Luca M Gambardella and Marco Dorigo. Ant-Q: A Reinforcement\nLearning Approach Traveling Salesman Problem. In Machine learn-\ning proceedings 1995 , pages 252â€“260. Elsevier, 1995.\n[31] Ruoying Sun, Shoji Tatsumi, and Gang Zhao. Multiagent Reinforce-\nment Learning Method with an Improved Ant Colony System. In\nProceedings of the IEEE International Conference on Systems, Man\n& Cybernetics , pages 1612â€“1617, 2001.\n[32] Fei Liu and Guangzhou Zeng. Study of Genetic Algorithm with\nReinforcement Learning to Solve the TSP. Expert Systems with\nApplications , 36(3):6995â€“7001, 2009.\n[33] YujiZou,,Jin-KaoHao,andQinghuaWu. Areinforcementlearning\nguidedhybridevolutionaryalgorithmforthelatencylocationrouting\nproblem. Computers & Operations Research , 170, 2024.\n[34] Florentin D. Hildebrandt, Barrett W. Thomas, and Marlin W. Ulmer.\nOpportunities for reinforcement learning in stochastic dynamic vehi-\ncle routing. Computers & Operations Research , 150, 2023.\n[35] Michael Held and Richard M. Karp. The Traveling-Salesman Prob-\nlem and Minimum Spanning Trees: Part II. Mathematical Program-\nming, 1(1):6â€“25, 1971.\n[36] Shivaram Kalyanakrishnan and Peter Stone. Efficient Selection of\nMultiple Bandit Arms: Theory and Practice. In Proceedings of the\n27thInternationalConferenceonMachineLearning ,pages511â€“518,\n2010.\n[37] Eduardo Uchoa, Diego Pecin, Artur Alves Pessoa, Marcus Poggi,\nThibaut Vidal, and Anand Subramanian. New benchmark instances\nfor the capacitated vehicle routing problem. European Journal of\nOperational Research , 257(3):845â€“858, 2017.\n[38] Marius Lindauer, Katharina Eggensperger, Matthias Feurer, AndrÃ©\nBiedenkapp, Difan Deng, Carolin Benjamins, Tim Ruhkopf, RenÃ©\nSass, and Frank Hutter. SMAC3: A Versatile Bayesian Optimization\nPackage for Hyperparameter Optimization. Journal of Machine\nLearning Research , 23(54):1â€“9, 2022.\nWang et al.: Preprint submitted to Elsevier Page 12 of 12",
  "structure": {
    "title": "Bandit based Dynamic Candidate Edge Selection in Solving Traveling",
    "abstract": "Algorithmsdesignedforroutingproblemstypicallyrelyonhigh-qualitycandidateedgestoguidetheir\nsearch, aimingto reduce thesearch space andenhance the searchefficiency. However, manyexisting\nalgorithms, like the classical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman\nProblem(TSP),oftenusepredeterminedcandidateedgesthatremainstaticthroughoutlocalsearches.\nThisrigiditycouldcausethealgorithmtogettrappedinlocaloptima,limitingitspotentialtofindbetter\nsolutions. To address this issue, we propose expanding the candidate sets to include other promising\nedges, providing them an opportunity for selection. Specifically, we incorporate multi-armed bandit\nmodels to dynamically select the most suitable candidate edges in each iteration, enabling LKH\nto make smarter choices and lead to improved solutions. Extensive experiments on multiple TSP\nbenchmarks show the excellent performance of our method. Moreover, we employ this bandit-based\nmethod to LKH-3, an extension of LKH tailored for solving various TSP variant problems, and our\nmethod also significantly enhances LKH-3â€™s performance across typical TSP variants.",
    "introduction": "The Traveling Salesman Problem (TSP) is a classic NP-\nhard combinatorial optimization problem. Given an undi-\nrected complete graph where the distance between each\npair of vertices (i.e., cities) is known, TSP aims to find the\nshortestpaththatstartsfromastartingcity,passeseachcity\nexactly once, and then returns to the starting city. As the\nbasic problem of many routing problems [1, 2, 3, 4, 5, 6],\nTSP also has many practical applications [7, 8].\nHeuristic algorithms are known to be most efficient for\nsolvingtheTSP,andtheycanbedividedintotwocategories:\nglobal search and local search. Global search methods [9]\nattempt to explore a wide solution space with a global\nperspective incorporating entropy in individual selection\nand partial crossover which are impressive in genetic al-\ngorithm [10, 11]. However, it is hard and time-consuming\nfor them to tackle super-large instances with huge solution\nspaces. Local search methods always maintain the current\nsolution and explore its neighborhood space, which are\nefficient and suitable for instances with various scales. In\nthispaper,wemainlyfocusonlocalsearchmethods,among\nwhichtheLin-Kernighan-Helsgaun(LKH)[12]algorithmis\noneofthemostrepresentativeandbest-performingmethods.\nTheLKHalgorithmisanoutstandingmethodamongthe\nLin-Kernighan(LK)[13]seriesthatcollectssomepromising\nedgesinthecandidatesetsofeachcityduringinitialization.\nWhen using the local search operators, such as ğ‘˜-opt, to\nadjustthecurrentsolution,theLK-basedalgorithmsrestrict\nâˆ—The first three authors contributed equally.\nâˆ— âˆ—Corresponding author.\nm202273734@hust.edu.cn (L. Wang); jzzheng@hust.edu.cn (J.\nZheng); xiongzd@hust.edu.cn (Z. Xiong); chumin.li@u-picardie.fr (C. Li);\nbrooklet60@hust.edu.cn (K. He)\nORCID(s):0000-0001-7627-4604 (K. He)the new edges to be added to belong to the candidate sets.\nTherefore, the algorithm performance heavily depends on\nthe quality of the candidate edges. LKH proposes an ef-\nfective metric called ğ›¼-value calculated based on a 1-tree\nstructure to select the candidate edges [14], resulting in its\nexcellent performance.\nHowever, the candidate edges in LKH are generally\npredetermined in the initialization stage and then keep un-\nchangedduringthesearchingprocess.Therefore,thecontent\nof each cityâ€™s candidate edges is relatively fixed, and LKH\nonlyassociateseachcitywithaboutafixednumberofcandi-\ndateedges(5bydefault).Althoughthe ğ›¼-valueispromising\nin evaluating the quality of the edges, once some crucial\nedges in the optimal solution are missed by the collected\ncandidate edges, it is hard for LKH to reach the global\noptimum. Simply enlarging the candidate sets allows the\nalgorithm to consider more edges, which, however, reduces\nthe efficiency significantly and may also contain some low-\nquality edges to mislead the search directions.\nIn this paper, we propose a novel method based on\nreinforcementlearningtoimprovetheLKHalgorithm,help-\ning it select the candidate edges more smartly and flexibly,\nproviding more edges the opportunity to serve as candidate\nedges. Specifically, we first expand the candidate sets of\neach city to a larger size and then select a subset of edges\nfrom the candidate sets to serve as candidate edges during\neach iteration. We associate each city with a multi-armed\nbandit(MAB),whereeacharmcorrespondstoanedgeinits\nenlarged candidate set and is associated with an evaluation\nvalue,denotedas ğ‘€-value.Theğ‘€-valueofanarmindicates\nthe benefit of selecting it as a candidate edge. The bandit\nmodels can learn from the searching process and update\ntheğ‘€-values. In each iteration of the algorithm, the bandit\nWang et al.: Preprint submitted to Elsevier Page 1 of 12arXiv:2505.15862v1 [cs.AI] 21 May 2025\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nmodelsrecommendappropriatecandidateedgesforthelocal\nsearch.\nMoreover,weemploythreedifferentstrategiesforselect-\ningthecandidateedges,i.e.,thearmsofthebandit.Thefirst\nstrategyappliesthe ğœ–-greedymethodtotrade-offexploration\nand exploitation, while the other two make the selection\ngreedily based on the ğ‘€-values andğ›¼-values, respectively.\nThethreestrategiesareusedcooperativelyduringthesearch\nto improve the robustness.\nWe apply our proposed method to LKH, denoting the\nresulting algorithm as Bandit-based LKH (bandLKH). Our",
    "methodology": "",
    "results": "",
    "conclusion": "",
    "full_text": "Bandit based Dynamic Candidate Edge Selection in Solving Traveling\nSalesman Problems\nLong Wanga,âˆ—, Jiongzhi Zhenga,âˆ—, Zhengda Xionga,âˆ—, ChuMin Liband Kun Hea,âˆ—âˆ—\naSchool of Computer Science and Technology, Huazhong University of Science and Technology, China 430074\nbMIS, University of Picardie Jules Verne, France 80039\nARTICLE INFO\nKeywords :\nTraveling salesman problems\nMulti-armed bandit\nCandidate set\nLin-Kernighan-Helsgaun algorithm\nLocal searchABSTRACT\nAlgorithmsdesignedforroutingproblemstypicallyrelyonhigh-qualitycandidateedgestoguidetheir\nsearch, aimingto reduce thesearch space andenhance the searchefficiency. However, manyexisting\nalgorithms, like the classical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman\nProblem(TSP),oftenusepredeterminedcandidateedgesthatremainstaticthroughoutlocalsearches.\nThisrigiditycouldcausethealgorithmtogettrappedinlocaloptima,limitingitspotentialtofindbetter\nsolutions. To address this issue, we propose expanding the candidate sets to include other promising\nedges, providing them an opportunity for selection. Specifically, we incorporate multi-armed bandit\nmodels to dynamically select the most suitable candidate edges in each iteration, enabling LKH\nto make smarter choices and lead to improved solutions. Extensive experiments on multiple TSP\nbenchmarks show the excellent performance of our method. Moreover, we employ this bandit-based\nmethod to LKH-3, an extension of LKH tailored for solving various TSP variant problems, and our\nmethod also significantly enhances LKH-3â€™s performance across typical TSP variants.\n1. Introduction\nThe Traveling Salesman Problem (TSP) is a classic NP-\nhard combinatorial optimization problem. Given an undi-\nrected complete graph where the distance between each\npair of vertices (i.e., cities) is known, TSP aims to find the\nshortestpaththatstartsfromastartingcity,passeseachcity\nexactly once, and then returns to the starting city. As the\nbasic problem of many routing problems [1, 2, 3, 4, 5, 6],\nTSP also has many practical applications [7, 8].\nHeuristic algorithms are known to be most efficient for\nsolvingtheTSP,andtheycanbedividedintotwocategories:\nglobal search and local search. Global search methods [9]\nattempt to explore a wide solution space with a global\nperspective incorporating entropy in individual selection\nand partial crossover which are impressive in genetic al-\ngorithm [10, 11]. However, it is hard and time-consuming\nfor them to tackle super-large instances with huge solution\nspaces. Local search methods always maintain the current\nsolution and explore its neighborhood space, which are\nefficient and suitable for instances with various scales. In\nthispaper,wemainlyfocusonlocalsearchmethods,among\nwhichtheLin-Kernighan-Helsgaun(LKH)[12]algorithmis\noneofthemostrepresentativeandbest-performingmethods.\nTheLKHalgorithmisanoutstandingmethodamongthe\nLin-Kernighan(LK)[13]seriesthatcollectssomepromising\nedgesinthecandidatesetsofeachcityduringinitialization.\nWhen using the local search operators, such as ğ‘˜-opt, to\nadjustthecurrentsolution,theLK-basedalgorithmsrestrict\nâˆ—The first three authors contributed equally.\nâˆ— âˆ—Corresponding author.\nm202273734@hust.edu.cn (L. Wang); jzzheng@hust.edu.cn (J.\nZheng); xiongzd@hust.edu.cn (Z. Xiong); chumin.li@u-picardie.fr (C. Li);\nbrooklet60@hust.edu.cn (K. He)\nORCID(s):0000-0001-7627-4604 (K. He)the new edges to be added to belong to the candidate sets.\nTherefore, the algorithm performance heavily depends on\nthe quality of the candidate edges. LKH proposes an ef-\nfective metric called ğ›¼-value calculated based on a 1-tree\nstructure to select the candidate edges [14], resulting in its\nexcellent performance.\nHowever, the candidate edges in LKH are generally\npredetermined in the initialization stage and then keep un-\nchangedduringthesearchingprocess.Therefore,thecontent\nof each cityâ€™s candidate edges is relatively fixed, and LKH\nonlyassociateseachcitywithaboutafixednumberofcandi-\ndateedges(5bydefault).Althoughthe ğ›¼-valueispromising\nin evaluating the quality of the edges, once some crucial\nedges in the optimal solution are missed by the collected\ncandidate edges, it is hard for LKH to reach the global\noptimum. Simply enlarging the candidate sets allows the\nalgorithm to consider more edges, which, however, reduces\nthe efficiency significantly and may also contain some low-\nquality edges to mislead the search directions.\nIn this paper, we propose a novel method based on\nreinforcementlearningtoimprovetheLKHalgorithm,help-\ning it select the candidate edges more smartly and flexibly,\nproviding more edges the opportunity to serve as candidate\nedges. Specifically, we first expand the candidate sets of\neach city to a larger size and then select a subset of edges\nfrom the candidate sets to serve as candidate edges during\neach iteration. We associate each city with a multi-armed\nbandit(MAB),whereeacharmcorrespondstoanedgeinits\nenlarged candidate set and is associated with an evaluation\nvalue,denotedas ğ‘€-value.Theğ‘€-valueofanarmindicates\nthe benefit of selecting it as a candidate edge. The bandit\nmodels can learn from the searching process and update\ntheğ‘€-values. In each iteration of the algorithm, the bandit\nWang et al.: Preprint submitted to Elsevier Page 1 of 12arXiv:2505.15862v1 [cs.AI] 21 May 2025\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nmodelsrecommendappropriatecandidateedgesforthelocal\nsearch.\nMoreover,weemploythreedifferentstrategiesforselect-\ningthecandidateedges,i.e.,thearmsofthebandit.Thefirst\nstrategyappliesthe ğœ–-greedymethodtotrade-offexploration\nand exploitation, while the other two make the selection\ngreedily based on the ğ‘€-values andğ›¼-values, respectively.\nThethreestrategiesareusedcooperativelyduringthesearch\nto improve the robustness.\nWe apply our proposed method to LKH, denoting the\nresulting algorithm as Bandit-based LKH (bandLKH). Our\nmethod expands the searching space, providing higher flex-\nibility for the search, assisting the LKH algorithm in es-\ncaping local optima and finding better solutions. We com-\npare bandLKH with the LKH baseline, as well as VSR-\nLKH[15]andNeuroLKH[16],tworepresentativelearning-\nbased algorithms. Extensive experiments in various bench-\nmarks show the superiority of bandLKH over LKH, VSR-\nLKH, and NeuroLKH. In particular, our method exhibits\nbetterperformanceandrobustnessthansimplyenlargingthe\ncandidate sets in LKH. The results indicate that our MAB\nmethod can effectively and smartly suggest high-quality\nedges and ignore low-quality ones.\nWe further apply our MAB method to the LKH-3 al-\ngorithm [17], an extension of LKH that can solve many\nTSP variant problems efficiently. The resulting algorithm is\ndenoted as bandLKH-3. We select two representative vari-\nant problem called Multiple Traveling Salesmen Problem\n(MTSP)andCapacitatedVehicleRoutingProblem(CVRP),\nandcompareourbandLKH-3withLKH-3.Theresultsshow\nthat our method can also significantly improve LKH-3 in\nMTSP and CVRP, indicating its excellent generalization\ncapability.\nThe main contributions of this paper are as follows.\nâ€¢We identified relatively rigid designs in the LKH\nalgorithm, i.e., the candidate edges for each city are\nrelatively fixed. We construct MAB models to select\nhigh-quality candidate edges adaptively during the\nsearching process from enlarged candidate sets. We\npropose three policies to choose candidates coordi-\nnately and a framework to train and utilize the MAB\nmodels. Our proposed methods and framework can\nbe applied to other heuristic algorithms for routing\nproblems needing to select candidate edges.\nâ€¢WecomparebandLKHwithLKHaswellasrepresen-\ntative learning-based algorithms for TSP on various\nbenchmarks.WealsogeneralizeourmethodtoLKH-\n3, which is an extension version of LKH for various\nTSP variants. Extensive experiments show the excel-\nlent performance and generalization capability of our\nmethod in TSP and its variant problems, MTSP and\nCVRP.\n2. Problem Definition\nIn this section, we present the definition of the involved\nproblems,includingtheTravelingSalesmanProblem(TSP),the Multiple TSP (MTSP), and the Capacitated Vehicle\nRouting Problem (CVRP).\n2.1. Traveling Salesman Problem\nGiven an undirected complete graph G(V,E), V is made\nup of cities in G numbered 1, 2, ..., n and E contains all\npairwise edges such as edge between city i and j presented\nby (i, j) which has its cost d(i,j). The aim is to find an\nhamiltonian circuit with a minimum total cost caculated byâˆ‘ğ‘›âˆ’1\nğ‘–=1(ğ‘‘(ğ‘–,ğ‘–+ 1)) +ğ‘‘(ğ‘›,1).\n2.2. Multiple TSP\nIn the MTSP, a set of ğ‘šsalesmen (or vehicles) are\navailable to visit a set of ğ‘›cities and each salesman starts\nand ends their route at a designated depot, with each city\nneeding to be visited exactly once by one of the salesmen.\nLetğ‘†= {1,2,â€¦,ğ‘š}be the set of salesmen and ğ¶=\n{1,2,â€¦,ğ‘›}bethesetofcities. ğ‘‡1,ğ‘‡2,â€¦,ğ‘‡ğ‘šarecomposed\nofğ‘šsubsetsğ¶1,ğ¶2,â€¦,ğ¶ğ‘šinğ¶. The goal is to minimizeâˆ‘ğ‘š\nğ‘˜=1âˆ‘\n(ğ‘–,ğ‘—)âˆˆğ‘‡ğ‘˜ğ‘‘(ğ‘–,ğ‘—).\n2.3. Capacitated Vehicle Routing Problem\nIn the CVRP, define m homogeneous fleets serving n\ncities have a max capacity ğ‘which could not be exceeded\nin each vehicle. Due to capacity, n cities are divided into m\nexclusive parts represented by ğ‘‡1,ğ‘‡2,â€¦,ğ‘‡ğ‘šbesides com-\nmonstartingandendingcities.Eachcustomerin ğ‘‡ğ‘–isvisited\nexactly once by one of the vehicles and common cities can\nbe visited many times. The total distance traveled by all\nvehicles,âˆ‘ğ‘š\nğ‘˜=1âˆ‘\n(ğ‘–,ğ‘—)âˆˆğ‘‡ğ‘˜ğ‘‘(ğ‘–,ğ‘—), is minimized.\n3. Related Work\nIn this section, we first review some related studies that\nsolve TSP with learning-based methods and then briefly\nintroduce some key components used in LKH.\n3.1. Learning-based Methods\nRecently, the application of learning-based methods,\nsuch as reinforcement learning and deep learning, for com-\nbinatorial optimization problems has become a highlight of\nresearch. TSP has even become a touchstone and one of the\nmost popular problems for learning-based methods.\nLearning-basedmethodsforTSPcanberoughlydivided\ninto two categories depending on whether deep learning\nis adopted. Actually, most learning-based methods try to\napplydeeplearningmethodsforTSPsolving.Typicalmeth-\nods include deep reinforcement learning and supervised\nlearning. For instance, some studies design or apply novel\ndeep learning structures for solving TSP, such as the multi-\npointer Transformer architecture called Pointerformer [18]\nand the hierarchical deep reinforcement learning frame-\nwork [19]. Some studies train neural networks to automate\nthe heuristic design, such as the Ant Colony Optimization\nandğ‘˜-opt[20,21,22]heuristics.TheNeuroLKHalgorithm\nutilizes a Sparse Graph Network to select candidate edges\nfor LKH [16], showing excellent performance in instances\nWang et al.: Preprint submitted to Elsevier Page 2 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nwithlessthan6,000cities.Aigerimproposeahybridmodel\ncombining an attention-based encoder and a Long Short-\nTermMemory(LSTM)decoderaddressingthechallengeof\nrouting a heterogeneous fleet. [23]. Bresson trains via deep\nreinforcementlearning,effectivelyaddressesthecombinato-\nrialoptimizationchallengesoftheTSP[24].GRLOS-Muses\nGraph Neural Networks to improve Adaptive Large Neigh-\nbourhood Search [25]. There are also some other famous\nmodelsandalgorithmsusingdeeplearningforTSP,suchas\nS2V-DQN [26], POMO [27], GLOP [28], etc.\nThe deep learning-based methods provide many new\nand interesting perspectives for solving TSP. However, they\nare usually hard to scale to large instances with tens of\nthousands of cities. The other category of method usually\nuses traditional reinforcement learning to accumulate the\nlearning information in tables and use them to guide the\nsearch.traditionalreinforcementlearningplaysanimportant\npartroleinTSP.MazyavkinasummarizedtheTSPproblem\nbasedonreinforcementlearning[29].Forexample,theAnt-\nQ [30] and Q-ACS [31] replace the pheromone in the ant\ncolony algorithm with the Q-table in the Q-learning algo-\nrithm.TheRMGAalgorithm[32]usesreinforcementlearn-\ning to construct mutation individuals in genetic algorithms.\nRLHEA combines Q-learning method with hybrid evolu-\ntionary algorithm for routing problem [33]. Moreover, the\nVSR-LKH [15] algorithm combines typical reinforcement\nlearning methods with LKH, altering and reordering the\ncandidateedges,showingexcellentperformanceinTSP.Re-\ninforcementlearningalsohasmanyopportunitiesinsolving\nstochastic dynamic vehicle routing problem [34].\nOur proposed method uses MAB models to select and\nadjust candidate edges during the local search. Compared\nto NeuroLKH and VSR-LKH, which also select and deter-\nmine the candidate edges before the local search process,\nour method provides more opportunity for other promising\nedges to be contained in candidate sets, allowing the algo-\nrithm to effectively solve instances with various scales and\nstructures.\n3.2. Key Components in LKH\n3.2.1. Theğ›¼-value\nCandidate edges are very important for LK-based local\nsearch algorithms since they decide the new edges that can\nbe added to the maintained solution. LKH proposes the ğ›¼-\nvalue for evaluating the edges and selecting the candidate\nedges. Theğ›¼-value is calculated based on a 1-tree struc-\nture [14], a variant of the spanning tree. Given a graph\nğº= (ğ‘‰,ğ¸), for any vertex ğ‘£âˆˆğ‘‰, we can generate a\n1-tree by first constructing a spanning tree on ğ‘‰âˆ–{ğ‘£}and\nthencombiningitwithtwoedgesfrom ğ¸incidenttoğ‘£.The\nminimum1-treeisthe 1-treewiththeminimumlength,i.e.,\nthe total length of its edges. We denote ğ¿(ğ‘‡)as the length\nof the minimum 1-tree, which is obviously a lower bound\nof the length of the shortest TSP tour. Moreover, we denote\nğ¿(ğ‘‡(ğ‘–,ğ‘—))as the length of the minimum 1-tree containing\nedge (ğ‘–,ğ‘—).Theğ›¼-valueofedge (ğ‘–,ğ‘—)iscalculatedasfollows.\n1\n2\n4 35\n6(a) Sequential 3-opt\nğ‘8\nğ‘3ğ‘4\nğ‘6ğ‘5ğ‘2ğ‘1ğ‘7 (b) Non-sequential 4-opt\nFigure 1: Examples of sequential and non-sequential ğ‘˜-opt\nmoves.\nğ›¼(ğ‘–,ğ‘—) =ğ¿(ğ‘‡(ğ‘–,ğ‘—)) âˆ’ğ¿(ğ‘‡). (1)\nTo further enhance the performance of ğ›¼-values, LKH\napplies the method of adding penalties [35] to vertices to\nobtain a tighter lower bound.\n3.2.2. Search Operators\nThe core search operator in LKH is the famous ğ‘˜-opt\nmethod,whichreplaces ğ‘˜edgesinthecurrentsolutionwith\nğ‘˜newedgesbasedontheejectchainmethod.Thatis,remove\nğ‘˜edges in the tour and attempt to rearrange the order of\nconnectionsamongthesepointstofindabettersolution.The\nğ‘˜-opt operator in LKH contains two categories, sequential\nandnon-sequentialmoves,asshowninFigure1.Thedashed\nlineistheedgethatisabouttobedisconnected.Thesequen-\ntial move starts from a starting point, e.g., ğ‘1, alternatively\nselects the edges to be removed, e.g., (ğ‘1,ğ‘2),(ğ‘3,ğ‘4)and\n(ğ‘5,ğ‘6), and edges to be added, e.g., (ğ‘2,ğ‘3)and(ğ‘4,ğ‘5),\nandguaranteesthatafterselectingeachedgetoberemoved,\nconnecting its endpoint, e.g., ğ‘4andğ‘6, back to the starting\npoint leads to a feasible TSP tour. Therefore, the sequential\nmove can be stopped once an improvement is found, and\nthe non-sequential move cannot. The non-sequential move\ncombines two distinct infeasible ğ‘˜-opt moves to form a\nfeasible tour, as shown in Figure 1(b). It is a supplement of\nthe sequential move, exploring additional search space that\nsequential moves cannot reach.\nIn summary, the search operators in LKH are encapsu-\nlated in the LinKernighan() function, which is an important\npartofexecutingLKalgorithm[13],followingtheguidance\nof the candidate edges to find moves that can improve the\ncurrentsolution.LinKernighan()finallyreturnsalocalopti-\nmalsolutionthatcannotbeimprovedbyanysearchoperators\nwith the candidate edges. For the detailed implementations\nof the LinKernighan() function, we referred to [12].\n4. Method\nThissectionpresentsourproposedbandLKHalgorithm.\nWefirstintroduceourmethodofusingmulti-armedbandits\n(MAB)toselectandrecommendcandidateedgesforthelo-\ncal search algorithm, then introduce the main framework of\nWang et al.: Preprint submitted to Elsevier Page 3 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nbandLKH, and finally introduce the method for calculating\nthe rewards and updating the bandit models.\n4.1. Candidate Edges Selection\nAs described in the introduction, our proposed MAB\nmodels select high-quality candidate edges from the en-\nlargedcandidatesets.NotethatLKHrestrictsthemaximum\nedges contained in each candidate set using a constant pa-\nrameterğ¶ğ‘šğ‘ğ‘¥,whosedefaultvalueis5.Suchadefaultvalue\nfits well with the algorithm, as a smaller value significantly\nreduces the search ability, and a larger value may contain\nlow-qualityedgesandreducethesearchefficiency.However,\nthe restriction of ğ¶ğ‘šğ‘ğ‘¥= 5may also miss some promising\nedges. Therefore, we propose to enlarge each candidate set\ntoalargersize(setting ğ¶ğ‘šğ‘ğ‘¥= 7bydefault),allowingmore\nedges to serve as candidate edges, and further use an MAB\nto ignore low-quality edges and select appropriate edges in\neach candidate set.\nIn the experiments, we perform an empirical analysis\nto evaluate the benefit of the expansion of candidate sets\nand a comparison showing that using our MAB to select\ncandidate edges from the enlarged candidate sets is more\nrobust and effective than regarding all edges in the enlarged\ncandidate sets as candidate edges directly, indicating the\nexcellent performance of our method.\nIn the following, we first introduce the proposed MAB\nmodelandthenthemethodofpullingthearmsinthebandit\nmodels.\n4.1.1. The MAB Model\nGiven the enlarged candidate set of each city, directly\nregarding all its edges as candidate edges will significantly\nreduce the algorithm efficiency and may contain some low-\nqualityedges.Thus,weneedtoselectsomeappropriateones\nfrom each enlarged candidate set. Such a task background\nsharessimilaritieswiththeMABmodel,whichalsoneedsto\nperformselectionsfrommultiplecandidatesandlacksprior\nknowledgeforselectingthebestonesineachstep.Thereare\nalso some differences between them, i.e., the candidate set\nneeds to produce multiple candidate edges and the MAB\nmodel usually only pulls one arm per step. Therefore, we\nestablishthetaskasavariantMABmodel[36],whichpulls\nmultiplearmseachtime.Specifically,weassociateeachcity\nwithanMAB,whereeacharmcorrespondstoanedgeinits\nenlargedcandidateset,andpullingeacharmcorrespondsto\nselect the corresponding edge as a candidate edge.\nFor each arm in each MAB, we assign it an evaluation\nvalue, denoted as ğ‘€-value. Theğ‘€-values are initialized to\nbe 0 in the beginning. The larger the ğ‘€-value of an arm,\nthe more the benefit of selecting it as a candidate edge.\nOur MAB models can learn from the search process and\nadjust theğ‘€-values, using them to recommend appropriate\ncandidate edges for the local search algorithm.\n4.1.2. Methods for Pulling the Arms\nIn our method, each MAB needs to pull ğ‘ğ‘ğ‘Ÿğ‘š(5 by\ndefaultequalsto ğ¶ğ‘šğ‘ğ‘¥ofLKH)armspercallingandrecom-\nmendsğ‘ğ‘ğ‘Ÿğ‘šcorrespondingcandidateedgestoparticipateinAlgorithm 1: CallBandit(ğœ–,ğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘ğ‘Ÿğ‘š)\nInput:ğœ–-greedy parameter: ğœ–, integer for\ndetermining the method: ğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ , number\nof pulled arms: ğ‘ğ‘ğ‘Ÿğ‘š\nOutput:Candidate edges ğ¸ğ‘ğ‘ğ‘›ğ‘‘\n1switchbandtype do\n2case0doselectğ¸ğ‘ğ‘ğ‘›ğ‘‘by theğœ–-greedy method;\n3case1doselectğ¸ğ‘ğ‘ğ‘›ğ‘‘bytheğ‘€-greedymethod;\n4case2doselectğ¸ğ‘ğ‘ğ‘›ğ‘‘by theğ›¼-greedy method;\n5returnğ¸ğ‘ğ‘ğ‘›ğ‘‘;\nthelocalsearchprocess.Wedesignthreemethodsforselect-\ning the arms to be pulled, denoted as ğœ–-greedy,ğ‘€-greedy,\nandğ›¼-greedy, respectively. Their formal descriptions are as\nfollows.\nâ€¢ğœ–-greedyrandomlyexplorestheedgesintheenlarged\ncandidate set with a probability of ğœ–(0< ğœ– < 1) and\nmakesagreedyselectionpreferringedgeswithlarger\nğ‘€-values with a probability of 1 âˆ’ğœ–.\nâ€¢ğ‘€-greedyselectsğ‘ğ‘ğ‘Ÿğ‘šedges with the largest ğ‘€-\nvalues greedily among each enlarged candidate set.\nâ€¢ğ›¼-greedyselectsğ‘ğ‘ğ‘Ÿğ‘šedgeswiththelargest ğ›¼-values\ngreedily among each enlarged candidate set.\nThe above three methods are used alternatively during\nthe search process. Actually, the ğ‘€-values and ğ›¼-values\nshare similarities and differences. Both of them serve as\nmetricsoftheedges.The ğ›¼-valuesarepredeterminedbefore\nthe local search process, evaluating the quality of the edges\nwith a global perspective. In contrast, the ğ‘€-values are\ncontinuously learned and updated during the local search\nprocess. We believe that these two metrics are complemen-\ntaryinevaluatingandselectingthecandidateedges,andthe\nutilizationofthe ğ‘€-greedyand ğ›¼-greedymethodscombine\ntheir complementarity. Moreover, the ğœ–-greedy allows the\nMABreinforcementlearningmodelstotrade-offexploration\nandexploitation.Experimentalresultsalsodemonstratethat\nthe combination of the three methods can improve the ro-\nbustness of the local search algorithm.\nGiven theğ‘€-values andğ›¼-values of the edges, the pa-\nrameterğœ–,anintegerğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ fordeterminingtheselection\nof the three methods, and the number of pulled arms per\ncalling of MAB ğ‘ğ‘ğ‘Ÿğ‘š, Algorithm 1 shows a CallBandit()\nfunction that calls the MAB models to select the candidate\nedges for the local search algorithm. The set of all selected\ncandidate edges is denoted as ğ¸ğ‘ğ‘ğ‘›ğ‘‘.\n4.2. Main Process of bandLKH\nAfter establishing the MAB model and the method for\nselecting candidate edges, we summarize the main frame-\nwork of bandLKH in this subsection, which is depicted\nin Algorithm 2. In the initialization stage (lines 1-5), the\nalgorithm initializes the enlarged candidate sets, the ğ‘€-\nvalues,andsomeinformationinvolvedinthesearchprocess.\nWang et al.: Preprint submitted to Elsevier Page 4 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nDuring the local search process (lines 6-19), the algorithm\nfirst generates an initial solution ğ‘…by function ChooseIni-\ntialTour() in LKH (line 7) and then calls the MAB models\nby function CallBandit() (Algorithm 1) to select the candi-\ndate edgesğ¸ğ‘ğ‘ğ‘›ğ‘‘(line 8). The selected ğ¸ğ‘ğ‘ğ‘›ğ‘‘will be used\nto guide the LinKernighan() function, which performs the\nsearch operators introduced in Section 3.2.2 to improve ğ‘…\nto a local optimum (line 9). The ğ‘€-values of the selected\ncandidate edges will be updated according to the quality of\ntheobtainedlocaloptimalsolution(line10).Moreover,ifthe\nbest solution ğ‘…âˆ—has not been improved for ğ‘‡ğ‘¡ğ‘¦ğ‘ğ‘’trials, the\nğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ willbechanged(line18)totrytousedifferentarm\nselection methods to help the algorithm escape from local\noptima.\nFor the time complexity, the additional operations of\nbandLKHoverLKHaretheCallBanditandUpdateMfunc-\ntions. CallBandit sorts the enlarged candidate set with size\nğ¶ğ‘šğ‘ğ‘¥(7 by default) of each city, costing a time complexity\nofğ‘‚(ğ‘›ğ¶ğ‘šğ‘ğ‘¥ğ‘™ğ‘œğ‘”(ğ¶ğ‘šğ‘ğ‘¥), whereğ‘›is the number of cities.\nUpdateM traverses the selected candidate edges once, cost-\ning a time complexity of ğ‘‚(ğ‘›). For the space complexity,\nbandLKH associates an ğ‘€-value with each candidate city,\ncosting a space complexity of ğ‘‚(ğ¶ğ‘šğ‘ğ‘¥ğ‘›). Therefore, both\nthe time and space complexities are of linear order and\nacceptable for large-scale problems.\nIn summary, the proposed bandLKH algorithm uses\nthe MAB models to help select candidate edges for the\nlocal search process. The MAB models select the candidate\nedges referring to the evaluation values of the arms, i.e.,\nğ‘€-values, and can learn from the searching process to\nupdatetheğ‘€-valuesandrecommendappropriateandhigh-\nquality candidate edges. The selected candidate edges can\nbeusedforvarioussearchoperatorsinLKHencapsulatedin\nthe LinKernighan() function, including sequential and non-\nsequential moves.\n4.3. Update the ğ‘€-values with Rewards\nTo update the evaluation values, i.e., ğ‘€-values, of the\narms in our MAB models, we need to design the reward\nfunctions for evaluating the benefit of pulling the arms, i.e.,\nselectingthecorrespondingcandidateedges.Suppose ğ‘…âˆ—is\nthe best solution found during the search process and ğ‘…is\nthe solution obtained by the function LinKernighan() based\nontheselectedcandidateedgesinthecurrenttrial.Asimple\nand straightforward reward function is designed as follows.\nğ‘Ÿ(ğ‘…,ğ‘…âˆ—) =ğ¿(ğ‘…âˆ—) âˆ’ğ¿(ğ‘…). (2)\nGiven the above reward function, the function Up-\ndateM() updates the ğ‘€-value of each selected candidate\nedge (ğ‘–,ğ‘—) âˆˆğ¸ğ‘ğ‘ğ‘›ğ‘‘in an incremental manner by the fol-\nlowing equation.\nğ‘€(ğ‘–,ğ‘—) = (1 âˆ’ğœ†)â‹…ğ‘€(ğ‘–,ğ‘—) +ğœ†â‹…ğ‘Ÿ(ğ‘…,ğ‘…âˆ—),(3)\nwhere 0<ğœ†< 1is the incremental reward parameter.Algorithm 2: bandLKH\nInput:A TSP instance: ğ¼, enlarged size of\ncandidate sets: ğ¶ğ‘šğ‘ğ‘¥, maximum number of\ntrials:ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘Ÿğ‘–ğ‘ğ‘™ğ‘  , the cut-off time:\nğ‘€ğ‘ğ‘¥ğ‘‡ğ‘–ğ‘šğ‘’ , number of pulled arms: ğ‘ğ‘ğ‘Ÿğ‘š,\nmaximum no-improvement trials for change\nğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ :ğ‘‡ğ‘¡ğ‘¦ğ‘ğ‘’,ğœ–-greedy parameter: ğœ–,\nincremental reward parameter: ğœ†\nOutput:The best solution found for ğ¼:ğ‘…âˆ—\n1Initialize each enlarged candidate set containing\nğ¶ğ‘šğ‘ğ‘¥edges based on ğ›¼-values;\n2Initialize length of the best solution ğ¿(ğ‘…âˆ—)â†+âˆ;\n3Initialize the number of no-improvement trials\nğ‘¡â†0;\n4Initializeğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ â†0;\n5Initialize the ğ‘€-values to 0;\n6forğ‘–â†1 âˆ¶ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘Ÿğ‘–ğ‘ğ‘™ğ‘  do\n7ğ‘…â†ChooseInitialTour();\n8ğ¸ğ‘ğ‘ğ‘›ğ‘‘â†CallBandit(ğœ–,ğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘ğ‘Ÿğ‘š);\n9ğ‘…â†LinKernighan( ğ¼,ğ‘…,ğ¸ğ‘ğ‘ğ‘›ğ‘‘);\n10UpdateM(ğ¸ğ‘ğ‘ğ‘›ğ‘‘,ğ‘…,ğ‘…âˆ—,ğœ†);\n11ifğ¿(ğ‘…)<ğ¿(ğ‘…âˆ—)then\n12ğ‘…âˆ—â†ğ‘…;\n13ğ‘¡â†0;\n14else\n15ğ‘¡â†ğ‘¡+ 1;\n16 ifğ‘¡â‰¥ğ‘‡ğ‘¡ğ‘¦ğ‘ğ‘’then\n17 ğ‘¡â†0;\n18 ğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ â†(ğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ + 1)%3;\n19ifrunning time >ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘–ğ‘šğ‘’ thenbreak ;\n20returnğ‘…âˆ—;\n5. Experiment\nIn this section, we first make a detailed comparison\nbetween bandLKH and LKH1(version 2.0.10) to evalu-\nate the performance of our proposed new algorithm. We\nalso compare bandLKH with representative learning-based\nmethods, including the deep learning-based NeuroLKH al-\ngorithm [16] and the traditional reinforcement learning-\nbasedVSR-LKHalgorithm[15].Wefurtherpresentablation\nstudies to evaluate the efficacy of components in bandLKH\nand provide further insights.\nFinally, we apply our method to LKH-3 [17], an exten-\nsionofLKHthatcansolvemanyTSPvariants.Theresulting\nsolver is called bandLKH-3. We select two representative\nvariants of TSP: the Multiple Traveling Salesmen Problem\n(MTSP), where the cities are visited by ğ‘šsalesmen, and\nthe goal is to minimize their total traveling distance, and\nthe Capacitated Vehicle Routing Problem (CVRP), which\nregards the salesmen and cities as vehicles with capacities\nandcustomerswithdemands,andthegoalistominimizethe\ntotal traveling distance of the vehicles while ensuring that\n1http://webhotel4.ruc.dk/ keld/research/LKH/\nWang et al.: Preprint submitted to Elsevier Page 5 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nTable 1\nDetailed comparison results of bandLKH and LKH. The best results appear in bold.\nInstance BKSLKH bandLKH\nSuccess Best (%) Average (%) Trials Time (s) Success Best (%) Average (%) Trials Time (s)\ngr137 69853 10/10 69853 (0.0000) 69853 (0.0000) 1.0 0.01 9/10 69853 (0.0000) 69865.7 (0.0182) 18.9 0.01\nch150 6528 9/10 6528 (0.0000) 6528.5 (0.0077) 60.1 0.05 10/10 6528 (0.0000) 6528 (0.0000) 23.3 0.08\nkroB150 26130 2/10 26130 (0.0000) 26131.6 (0.0061) 128.4 0.24 10/10 26130 (0.0000) 26130 (0.0000) 54.1 0.21\nsi175 21407 7/10 21407 (0.0000) 21407.3 (0.0014) 105.9 6.15 9/10 21407 (0.0000) 21407.1 (0.0005) 35.3 4.95\nrat195 2323 9/10 2323 (0.0000) 2323.5 (0.0215) 55.0 0.15 10/10 2323 (0.0000) 2323 (0.0000) 14.8 0.19\ngr229 134602 2/10 134602 (0.0000) 134613.2 (0.0083) 203.1 0.20 10/10 134602 (0.0000) 134602 (0.0000) 25.9 0.14\npr299 48191 9/10 48191 (0.0000) 48194.3 (0.0068) 51.7 0.36 10/10 48191 (0.0000) 48191 (0.0000) 21.6 0.68\nlin318 42029 4/10 42029 (0.0000) 42085.4 (0.1342) 249.3 0.55 9/10 42029 (0.0000) 42040.4 (0.0271) 53.0 0.34\ngr431 171414 3/10 171414 (0.0000) 171499.2 (0.0497) 347.0 1.73 10/10 171414 (0.0000) 171414 (0.0000) 73.7 2.26\nd493 35002 2/10 35002 (0.0000) 35003.6 (0.0046) 419.3 2.62 10/10 35002 (0.0000) 35002 (0.0000) 28.2 0.98\nsi535 48450 7/10 48450 (0.0000) 48451.1 (0.0023) 311.6 21.28 9/10 48450 (0.0000) 48450.3 (0.0006) 138.9 31.98\nrat575 6773 2/10 6773 (0.0000) 6773.8 (0.0118) 526.9 2.32 6/10 6773 (0.0000) 6773.4 (0.0059) 392.5 4.93\ngr666 294358 5/10 294358 (0.0000) 294417 (0.0200) 459.8 2.41 6/10 294358 (0.0000) 294393.7 (0.0121) 372.9 10.01\npr1002 259045 8/10 259045 (0.0000) 259045.6 (0.0002) 549.0 3.13 10/10 259045 (0.0000) 259045 (0.0000) 90.7 2.83\nu1060 224094 5/10 224094 (0.0000) 224107.5 (0.0060) 663.3 84.17 10/10 224094 (0.0000) 224094 (0.0000) 44.4 22.00\nvm1084 239297 3/10 239297 (0.0000) 239372.6 (0.0316) 824.1 32.98 8/10 239297 (0.0000) 239307.4 (0.0043) 323.9 26.51\npcb1173 56892 4/10 56892 (0.0000) 56895 (0.0053) 844.0 3.92 8/10 56892 (0.0000) 56893 (0.0018) 418.4 9.79\nd1291 50801 5/10 50801 (0.0000) 50840 (0.0768) 995.4 27.44 10/10 50801 (0.0000) 50801 (0.0000) 192.2 14.74\nrl1304 252948 3/10 252948 (0.0000) 253156.4 (0.0824) 1170.0 12.48 10/10 252948 (0.0000) 252948 (0.0000) 572.1 27.38\nrl1323 270199 6/10 270199 (0.0000) 270219.6 (0.0076) 718.8 9.63 8/10 270199 (0.0000) 270204.4 (0.0020) 576.9 23.75\nnrw1379 56638 6/10 56638 (0.0000) 56640 (0.0035) 759.3 8.87 6/10 56638 (0.0000) 56639.6 (0.0028) 928.0 35.27\nfl1400 20127 0/10 20164 (0.1838) 20165.5 (0.1913) 1400.0 113.30 6/10 20127 (0.0000) 20141.8 (0.0735) 721.0 219.18\nfl1577 22249 0/10 22254 (0.0225) 22260.6 (0.0521) 1577.0 1172.10 9/10 22249 (0.0000) 22249.5 (0.0022) 614.9 1920.79\nvm1748 336556 9/10 336556 (0.0000) 336557.3 (0.0004) 1007.9 12.69 10/10 336556 (0.0000) 336556 (0.0000) 146.4 9.99\nu1817 57201 1/10 57201 (0.0000) 57251.1 (0.0876) 1817.0 74.19 1/10 57201 (0.0000) 57237.3 (0.0635) 1750.3 260.67\nrl1889 316536 0/10 316549 (0.0041) 316549.8 (0.0044) 1889.0 61.40 10/10 316536 (0.0000) 316536 (0.0000) 236.5 35.56\nd2103 80450 0/10 80471 (0.0261) 80505.7 (0.0692) 2103.0 67.07 7/10 80450 (0.0000) 80451 (0.0012) 1084.0 306.06\nu2152 64253 3/10 64253 (0.0000) 64287.7 (0.0540) 1614.0 73.81 8/10 64253 (0.0000) 64264.4 (0.0177) 793.6 135.39\npcb3038 137694 4/10 137694 (0.0000) 137701.2 (0.0052) 2078.6 69.56 5/10 137694 (0.0000) 137700.7 (0.0049) 2081.1 275.37\nfl3795 28772 4/10 28772 (0.0000) 28783.2 (0.0389) 2998.1 423.94 5/10 28772 (0.0000) 28778.5 (0.0226) 3012.3 2437.03\nfnl4461 182566 9/10 182566 (0.0000) 182566.5 (0.0003) 923.1 31.05 10/10 182566 (0.0000) 182566 (0.0000) 153.4 37.02\nrl5915 565530 1/10 565530 (0.0000) 565621.5 (0.0162) 5915.0 242.05 3/10 565530 (0.0000) 565564.4 (0.0061) 4863.8 1663.58\nrl5934 556045 0/10 556172 (0.0228) 556377.6 (0.0598) 5934.0 305.02 8/10 556045 (0.0000) 556063.2 (0.0033) 3472.1 1607.18\nxmc10150 28387 0/5 28388 (0.0035) 28388.8 (0.0063) 10000.0 832.77 0/5 28389 (0.0070) 28390.8 (0.0134) 10000.0 4279.32\nfi10639 520527 0/5 520534 (0.0013) 520562.8 (0.0069) 10000.0 844.41 0/5 520539 (0.0023) 520564.2 (0.0071) 10000.0 4636.34\nrl11849 923288 1/5 923288 (0.0000) 923360.2 (0.0078) 9257.4 947.41 1/5 923288 (0.0000) 923323.6 (0.0039) 8532.0 3633.09\nusa13509 19982859 0/5 19982874 (0.0001) 19983306.2 (0.0022) 10000.0 1111.75 0/5 19983027 (0.0008) 19983277.2 (0.0021) 10000.0 6300.91\nxvb13584 37083 1/5 37083 (0.0000) 37087.2 (0.0113) 8251.2 1053.74 0/5 37086 (0.0081) 37090.4 (0.0200) 10000.0 5740.31\nbrd14051 469385 0/5 469395 (0.0021) 469397.4 (0.0026) 10000.0 1789.55 0/5 469412 (0.0058) 469460.6 (0.0161) 10000.0 8240.87\nmo14185 427377 0/5 427381 (0.0009) 427402.6 (0.0060) 10000.0 1408.07 0/5 427380 (0.0007) 427385.8 (0.0021) 10000.0 6173.50\nxrb14233 45462 0/5 45466 (0.0088) 45468.4 (0.0141) 10000.0 1376.69 1/5 45462 (0.0000) 45465 (0.0066) 10000.0 6659.30\nho14473 177092 0/5 177161 (0.0390) 177182.6 (0.0512) 332.2 43362.26 0/5 177117 (0.0141) 177138 (0.0260) 402.8 43336.19\nd15112 1573084 0/5 1573202 (0.0075) 1573242.6 (0.0101) 10000.0 2109.11 0/5 1573288 (0.0130) 1573318.8 (0.0149) 10000.0 9560.62\nit16862 557315 0/5 557319 (0.0007) 557336 (0.0038) 10000.0 6012.14 0/5 557319 (0.0007) 557332.4 (0.0031) 8975.0 39870.58\nxia16928 52850 1/5 52850 (0.0000) 52853.2 (0.0061) 10000.0 1673.98 1/5 52850 (0.0000) 52852 (0.0038) 10000.0 9295.23\npjh17845 48092 0/5 48093 (0.0021) 48100.4 (0.0175) 10000.0 1739.08 0/5 48093 (0.0021) 48095.6 (0.0075) 10000.0 10022.94\nd18512 645238 0/5 645263 (0.0039) 645268.8 (0.0048) 10000.0 2668.68 0/5 645353 (0.0178) 645424.4 (0.0289) 10000.0 10513.63\nfrh19289 55798 0/5 55800 (0.0036) 55806.8 (0.0158) 10000.0 1836.78 0/5 55804 (0.0108) 55808.8 (0.0194) 10000.0 11312.59\nfnc19402 59287 0/5 59303 (0.0270) 59308.6 (0.0364) 10000.0 1823.40 0/5 59295 (0.0135) 59298.6 (0.0196) 10000.0 9574.85\nido21215 63517 0/5 63525 (0.0126) 63533.6 (0.0261) 10000.0 2161.70 0/5 63519 (0.0031) 63525.6 (0.0135) 10000.0 14603.81\nfma21553 66527 0/5 66529 (0.0030) 66540.4 (0.0201) 10000.0 2102.46 1/5 66527 (0.0000) 66534.8 (0.0117) 10000.0 11584.06\nvm22775 569288 0/5 569299 (0.0019) 569308.6 (0.0036) 10000.0 7171.50 0/5 569290 (0.0004) 569308.8 (0.0037) 10000.0 20219.20\nlsb22777 60977 0/5 60981 (0.0066) 60989 (0.0197) 10000.0 2625.61 0/5 60978 (0.0016) 60983.8 (0.0112) 10000.0 15632.94\nxrh24104 69294 0/5 69300 (0.0087) 69304.2 (0.0147) 10000.0 2303.96 0/5 69297 (0.0043) 69303.2 (0.0133) 10000.0 16508.96\nsw24978 855597 0/5 855599 (0.0002) 855628 (0.0036) 10000.0 2807.11 0/5 855602 (0.0006) 855611.8 (0.0017) 10000.0 17463.64\nbbz25234 69335 0/5 69343 (0.0115) 69349.8 (0.0213) 10000.0 2938.86 0/5 69340 (0.0072) 69346.2 (0.0162) 10000.0 21084.39\nirx28268 72608 0/5 72614 (0.0083) 72622 (0.0193) 10000.0 2979.10 1/5 72608 (0.0000) 72610.2 (0.0030) 10000.0 17642.29\nfyg28534 78562 0/5 78571 (0.0115) 78574.6 (0.0160) 10000.0 2941.72 0/5 78568 (0.0076) 78573.2 (0.0143) 10000.0 21597.03\nicx28698 78087 0/5 78100 (0.0166) 78106.8 (0.0254) 10000.0 3237.22 0/5 78093 (0.0077) 78104.4 (0.0223) 10000.0 22079.87\nird29514 80353 0/5 80366 (0.0162) 80374.8 (0.0271) 10000.0 3052.62 0/5 80380 (0.0336) 80392.4 (0.0490) 10000.0 24177.14\npla33810 66048945 0/5 66061689 (0.0193) 66065656.2 (0.0253) 3000.0 25030.56 0/5 66052269 (0.0050) 66062745 (0.0209) 1442.4 29411.21\npla85900 142382641 0/5 142455345 (0.0511) 142457070.8 (0.0523) 3000.0 9270.29 0/5 142404864 (0.0156) 142411899.2 (0.0205) 3000.0 25842.53\nAverage Gap (%) - - 0.0085 0.0249 - - - 0.0030 0.0107 - -\nTable 2\nSummarized comparison results of bandLKH and learning-based methods, VSR-LKH and NeuroLKH. The best results appear in\nbold.\nIndicator bandLKH VSR-LKH bandLKH NeuroLKH_R bandLKH NeuroLKH_M\nğ‘Šğ‘–ğ‘›ğ‘ğ‘’ğ‘ ğ‘¡ 2 0 8 0 5 0\nğ‘Šğ‘–ğ‘›ğ‘ğ‘£ğ‘” 13 9 22 8 13 9\nğºğ‘ğ‘ğ‘ğ‘’ğ‘ ğ‘¡ 0.0000% 0.0027% 0.0000% 0.0215% 0.0000% 0.0803%\nğºğ‘ğ‘ğ‘ğ‘£ğ‘” 0.0036% 0.0060% 0.0043% 0.0366% 0.0043% 0.0834%\neach customerâ€™s demand is satisfied and the total demand\ndoes not exceed the capacity of any vehicle. We compare\nbandLKH-3 with LKH-3 in solving MTSP and CVRP and\nevaluate the generalization capability of our method.\n5.1. Experimental Setup\nbandLKH was implemented in C Programming Lan-\nguage.TheexperimentswererunonaserverusinganAMDEPYC 7H12 CPU, running Ubuntu 18.04 Linux operation\nsystem.Wetestedthealgorithmsinallthe82symmetryTSP\ninstancesfromtheTSPLIB2benchmarkwiththenumberof\ncities ranging from 101 to 85,900, and all the 22 instances\nwith the number of cities ranging from 10,000 to 30,000\n2http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/\nWang et al.: Preprint submitted to Elsevier Page 6 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nTable 3\nSummarized comparison results of bandLKH and its variants, bandLKH-no ğœ–, bandLKH-no ğ‘€, and bandLKH-no ğ›¼. The best results\nappear in bold.\nIndicator bandLKH bandLKH-no ğœ–bandLKH bandLKH-no ğ‘€bandLKH bandLKH-no ğ›¼\nğ‘Šğ‘–ğ‘›ğ‘ğ‘’ğ‘ ğ‘¡ 0 0 0 0 2 0\nğ‘Šğ‘–ğ‘›ğ‘ğ‘£ğ‘” 12 7 6 12 28 4\nğºğ‘ğ‘ğ‘ğ‘’ğ‘ ğ‘¡ 0.0000% 0.0000% 0.0000% 0.0000% 0.0000% 0.0006%\nğºğ‘ğ‘ğ‘ğ‘£ğ‘” 0.0036% 0.0044% 0.0036% 0.0057% 0.0036% 0.0076%\nTable 4\nSummarized comparison results between bandLKH with LKH-\nğ‘ğ‘ğ‘Ÿğ‘šand LKH-ğ¶ğ‘šğ‘ğ‘¥. The best results appear in bold.\nIndicator bandLKH LKH- ğ¶ğ‘šğ‘ğ‘¥\nğ‘Šğ‘–ğ‘›ğ‘ğ‘’ğ‘ ğ‘¡ 1 0\nğ‘Šğ‘–ğ‘›ğ‘ğ‘£ğ‘” 19 12\nğºğ‘ğ‘ğ‘ğ‘’ğ‘ ğ‘¡ 0.0000% 0.0001%\nğºğ‘ğ‘ğ‘ğ‘£ğ‘” 0.0036% 0.0057%\nfrom the National TSPs3and VLSI TSPs4benchmarks. We\nalso use the 82 instances from TSPLIB with ğ‘š= 3as\nthe MTSP benchmarks. A TSP instance can be transformed\ninto an MTSP instance by regarding the first city as the\ndepot. Note that the number in the name of a TSP instance\nindicates the number of cities it contains. For CVRP, we\ntested LKH-3 and bandLKH-3 in the dataset proposed by\nUchoaetal.[37]5containing100instanceswiththenumber\nof customers ranging from 100 to 1,001.\nWe set the cut-off time ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘–ğ‘šğ‘’ and the maximum\nnumber of iterations ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘Ÿğ‘–ğ‘ğ‘™ğ‘  to be the same for the\nalgorithms.ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘Ÿğ‘–ğ‘ğ‘™ğ‘  issettothenumberofcities(default\nsettings in LKH and LKH-3) for instances with less than\n10,000 cities, 10,000 for instances with more than 10,000\ncities, and 3,000 for instances with more than 30,000 cities.\nEach TSP instance with less than 10,000 cities was run 10\ntimes by each algorithm with different random seeds. The\nrest of the instances were run 5 times by each algorithm.\nğ‘€ğ‘ğ‘¥ğ‘‡ğ‘–ğ‘šğ‘’ issettoonedayforalltheinstances.Ineachrun,\nthe algorithm will terminate and start the next run when it\nfinds the optimal solution.\nParameters related to the MAB in bandLKH and\nbandLKH-3 include the enlarged size of candidate sets:\nğ¶ğ‘šğ‘ğ‘¥, the number of pulled arms in each bandit: ğ‘ğ‘ğ‘Ÿğ‘š,\nthe maximum no-improvement trials for change ğ‘ğ‘ğ‘›ğ‘‘ğ‘¡ğ‘¦ğ‘ğ‘’ :\nğ‘‡ğ‘¡ğ‘¦ğ‘ğ‘’,theğœ–-greedyparameter: ğœ–,andtheincrementalreward\nparameter:ğœ†. We adopted an automatic configurator called\nSMAC3[38]totunethembasedonsomesampledinstances,\nandtheirdefaultsettingsareasfollows: ğ¶ğ‘šğ‘ğ‘¥= 7,ğ‘ğ‘ğ‘Ÿğ‘š= 5,\nğ‘‡ğ‘¡ğ‘¦ğ‘ğ‘’=ğ‘€ğ‘ğ‘¥ğ‘‡ğ‘Ÿğ‘–ğ‘ğ‘™ğ‘  âˆ•20by referring to VSR-LKH, ğœ–=\n0.15, andğœ†= 0.16. Other parameters are the same as those\nin LKH and LKH-3. The tuning domains of ğ¶ğ‘šğ‘ğ‘¥,ğœ–, and\n3https://www.math.uwaterloo.ca/tsp/world/countries.html\n4https://www.math.uwaterloo.ca/tsp/vlsi/index.html\n5http://www.vrp-rep.org/datasets/item/2016-0019.htmlğœ†are[6,8],[0.05,0.06,...,0.30], and [0.05,0.06,...,0.30],\nrespectively.\n5.2. Comparison of bandLKH and LKH\nThissubsectioncomparesbandLKHandLKH.Actually,\nLKH selects 5 fixed candidate edges for each city, and\nbandLKH selects ğ‘ğ‘ğ‘Ÿğ‘š= 5more appropriate candidate\nedges in a larger candidate set (with size equals ğ¶ğ‘šğ‘ğ‘¥= 7)\nfor each city using the proposed MAB model.\nThe detailed comparison results between bandLKH and\nLKHareshowninTable1.Column ğµğ¾ğ‘†indicatesthebest-\nknownsolutionsoftheinstances,andweonlypresentallthe\n62 instances in which at least one of LKH and bandLKH\ncannot obtain the ğµğ¾ğ‘†in each run. Actually, the ğµğ¾ğ‘†\nof tested instances from TSPLIB and National TSPs have\nbeen proven to be optimal. Column Successindicates the\nsuccess rate to find the ğµğ¾ğ‘†, columns BestandAverage\nindicate the best and average solutions of the algorithms,\nrespectively, with their gaps to the ğµğ¾ğ‘†placed in the\nbrackets, and columns TrialsandTimeindicate the average\ntrialsandrunningtimeofthealgorithms.Wefurtherpresent\ntheaveragegapofthebestandaveragesolutionstothe ğµğ¾ğ‘†\nat the bottom of Table 1.\nThe results show that bandLKH obtains better (resp.\nworse) results in terms of the success rate in 33 (resp. 1)\ninstances and better (resp. worse) results in terms of the\naverage solution in 52 (resp. 10) instances. The average gap\nof the best (resp. average) solutions obtained by bandLKH\nto theğµğ¾ğ‘†is about 65% (resp. 57) smaller than that\nof LKH. We can also observe that bandLKH significantly\noutperforms LKH in solving instances with various scales.\nThe results indicate that bandLKH has significantly better\nperformance and robustness than LKH.\n5.3. Comparison with Learning-based Methods\nTo further show the performance and advantage of our\nlearning method, we compare bandLKH with the state-of-\nthe-art learning-based methods for TSP, including the Neu-\nroLKH algorithm [16], which combines deep learning and\nLKH, and the VSR-LKH algorithm [15], which combines\ntraditional reinforcement learning with LKH. We compare\nbandLKH with two versions of NeuroLKH, NeuroLKH_R\nand NeuroLKH_M, which were trained in instances with\nuniformly distributed nodes and a mixture of instances\nwith uniformly distributed nodes, clustered nodes, half uni-\nform and half clustered nodes, respectively. We compare\nbandLKH with VSR-LKH in 75 TSPLIB instances whose\nWang et al.: Preprint submitted to Elsevier Page 7 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nTable 5\nDetailed comparison of LKH3 and bandLKH-3 on CVRP. The best results appear in bold.\nLKH-3 bandLKH-3\nInstance Best Average Trials Time(s) Best Average Trials Time(s)\nX-n101-k25 27653 27717.4 10000.0 56.48 27591 27625 7393.0 19.872\nX-n106-k14 26389 26482.2 10000.0 50.67 26386 26388.2 10000.0 61.72\nX-n110-k13 14971 14971 1271.0 0.37 14971 14971 2048.0 0.698\nX-n115-k10 12747 12754 5159.0 1.76 12747 12747 314.0 0.069\nX-n120-k6 13332 13351.5 6011.0 3.03 13340 13374.4 10000.0 12.692\nX-n125-k30 55736 55880.4 10000.0 161.35 55675 55812.2 10000.0 167.218\nX-n129-k18 28958 29034.4 10000.0 38.26 28957 29049.4 10000.0 47.892\nX-n134-k13 10933 10985.2 10000.0 39.71 10918 10964.4 10000.0 50.12\nX-n139-k10 13590 13590 1167.0 0.33 13612 13641 10000.0 16.549\nX-n143-k7 15726 15774.4 10000.0 24.08 15726 15789.6 10000.0 29.478\nX-n148-k46 43448 43448 5442.0 5.01 43594 43706.8 10000.0 50.921\nX-n153-k22 21254 21290.6 10000.0 71.11 21247 21275.4 10000.0 87.463\nX-n157-k13 16876 16885 5339.0 3.22 16876 16876 2229.0 1.007\nX-n162-k11 14138 14196.75 8457.2 8.98 14153 14167.4 10000.0 15.617\nX-n167-k10 20637 20752 10000.0 30.91 20610 20742.4 10000.0 34.993\nX-n172-k51 45733 45830.2 10000.0 58.51 45637 45806.2 10000.0 65.726\nX-n176-k26 48076 48217.8 10000.0 157.76 47895 48041.4 10000.0 186.436\nX-n181-k23 25572 25628 10000.0 18.02 25576 25626.4 10000.0 24.256\nX-n186-k15 24279 24304 10000.0 52.09 24212 24394.2 10000.0 55.446\nX-n190-k8 17041 17197.4 10000.0 40.08 17031 17173.6 10000.0 47.873\nX-n195-k51 44322 44432 10000.0 51.65 44480 44527.4 10000.0 69.822\nX-n200-k36 58882 58934.4 10000.0 155.41 58819 58901.4 10000.0 214.636\nX-n204-k19 19699 19746.4 10000.0 22.49 19610 19696.4 10000.0 28.873\nX-n209-k16 30855 31031.8 10000.0 44.07 31043 31117 10000.0 50.978\nX-n214-k11 11138 11252.2 10000.0 107.32 11089 11189.2 10000.0 116.901\nX-n219-k73 117613 117675.2 10000.0 45.03 117613 117685.4 10000.0 1142.35\nX-n223-k34 40704 40804.6 10000.0 59.50 40688 40799.8 10000.0 71.578\nX-n228-k23 25782 25906.6 10000.0 69.01 25806 25869.8 10000.0 73.489\nX-n233-k16 19365 19465.2 10000.0 16.56 19313 19411.4 10000.0 22.386\nX-n237-k14 27128 27266.8 10000.0 29.61 27050 27165.2 10000.0 36.486\nX-n242-k48 83121 83468.8 10000.0 91.32 83197 83358 10000.0 107.912\nX-n247-k47 37353 37487.8 10000.0 114.37 37290 37337.8 10000.0 155.195\nX-n251-k28 38914 39040.4 10000.0 52.43 38812 39008 10000.0 67.16\nX-n256-k16 19062 19207.4 10000.0 70.77 19000 19213.2 10000.0 78.19\nX-n261-k13 26808 27075.2 10000.0 63.92 26948 27088.6 10000.0 89.908\nX-n266-k58 75795 76074.6 10000.0 160.84 75948 76111 10000.0 194.644\nX-n270-k35 35504 35566.8 10000.0 62.32 35506 35702.8 10000.0 75.149\nX-n275-k28 21347 21418.4 10000.0 22.63 21347 21426 10000.0 26.471\nX-n280-k17 33835 33921.6 10000.0 102.88 33725 33878 10000.0 130.435\nX-n284-k15 20348 20640 10000.0 36.72 20401 20514.6 10000.0 38.847\nX-n289-k60 96038 96238.8 10000.0 255.37 95983 96199.6 10000.0 298.468\nX-n294-k50 47473 47637 10000.0 74.52 47508 47654.8 10000.0 97.423\nX-n298-k31 34522 34776.6 10000.0 54.44 34431 34581.6 10000.0 67.207\nX-n303-k21 21919 22008.2 10000.0 36.47 21906 22027.4 10000.0 40.758\nX-n308-k13 26208 26266.6 10000.0 63.42 26022 26231 10000.0 64.52\nX-n313-k71 95087 95197.2 10000.0 250.89 94880 94950.4 10000.0 294.031\nnumber of cities ranges from 101 to 10,000 and compare\nbandLKHwithNeuroLKHin60TSPLIBinstancesreported\ninitspaper.ThesummarizedresultsareallshowninTable2.\nAs shown in Table 2, bandLKH obtains better results\nthan VSR-LKH in 2 (resp. 13) instances in terms of the\nbest (resp. average) solutions and worse results than VSR-\nLKH in 0 (resp. 9) instances in terms of the best (resp.\naverage) solutions. Moreover, bandLKH obtains better re-\nsults than NeuroLKH_R in 8 (resp. 21) instances in terms\nof the best (resp. average) solutions and worse results than\nNeuroLKH_R in 1 (resp. 8) instances in terms of the best\n(resp. average) solutions, and bandLKH obtains better re-\nsults than NeuroLKH_M in 5 (resp. 13) instances in terms\nof the best (resp. average) solutions and worse results thanNeuroLKH_M in 1 (resp. 9) instances in terms of the best\n(resp. average) solutions.\nThe results in Table 2 indicate that bandLKH has a\nsuperiorityoverthestate-of-the-artlearning-basedmethods,\nVSR-LKH and NeuroLKH. Note that NeuroLKH uses deep\nlearningmethodstohelpLKHselectcandidateedgesbefore\nlocal search, and VSR-LKH uses traditional reinforcement\nlearning to adjust the order of the candidate edges during\nthesearch.Therefore,neitherofthemchangesthecandidate\nedges of each city. The proposed bandLKH algorithm can\ndynamically suggest candidate edges from enlarged candi-\ndate sets, providing more flexibility for the algorithm and\nWang et al.: Preprint submitted to Elsevier Page 8 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nTable 6\nDetailed comparison of LKH3 and bandLKH-3 on CVRP (continued). The best results appear in bold.\nLKH-3 bandLKH-3\nInstance Best Average Trials Time(s) Best Average Trials Time(s)\nX-n317-k53 78389 78608.6 10000.0 78.26 78458 78679.6 10000.0 106.873\nX-n322-k28 30228 30369.4 10000.0 72.03 30233 30263.6 10000.0 83.37\nX-n327-k20 27887 28015.8 10000.0 58.75 28027 28078.8 10000.0 73.938\nX-n331-k15 31488 31565 10000.0 30.20 31393 31608.8 10000.0 40.726\nX-n336-k84 140006 140344.8 10000.0 231.94 140023 140283.4 10000.0 282.161\nX-n344-k43 42502 42682.6 10000.0 78.53 42551 42720.2 10000.0 98.49\nX-n351-k40 26261 26333.4 10000.0 102.05 26236 26308 10000.0 128.196\nX-n359-k29 52210 52284.8 10000.0 106.94 52061 52329.8 10000.0 136.523\nX-n367-k17 23163 23290 10000.0 48.84 23113 23240.4 10000.0 60.611\nX-n376-k94 147877 147982.2 10000.0 77.43 147840 147953.2 10000.0 93.745\nX-n384-k52 66514 66668 10000.0 136.75 66656 66833.2 10000.0 166.046\nX-n393-k38 38633 38816 10000.0 76.18 38656 38772 10000.0 95.672\nX-n401-k29 66619 66781.6 10000.0 241.04 66581 66720.4 10000.0 281.493\nX-n411-k19 20083 20165.4 10000.0 76.96 19883 19950.8 10000.0 86.724\nX-n429-k61 66136 66427.8 10000.0 108.46 66257 66419 10000.0 145.347\nX-n439-k37 36656 36755.6 10000.0 21.44 36554 36642.4 10000.0 27.291\nX-n449-k29 56523 56680.6 10000.0 318.24 56550 56697.8 10000.0 364.509\nX-n459-k26 24559 24729.8 10000.0 108.59 24507 24681.8 10000.0 126.728\nX-n469-k138 223805 224058.6 10000.0 419.96 223683 223783 10000.0 861.448\nX-n480-k70 90205 90413 10000.0 133.73 90086 90233.4 10000.0 154.667\nX-n491-k59 67539 67781.2 10000.0 304.39 67598 67780.8 10000.0 376.552\nX-n502-k39 69348 69423.4 10000.0 38.80 69417 69463 10000.0 46.82\nX-n513-k21 24589 24674.4 10000.0 30.34 24532 24623.6 10000.0 34.59\nX-n536-k96 96180 96890.8 10000.0 800.66 96131 96375.2 10000.0 935.67\nX-n548-k50 87203 87308.8 10000.0 85.52 87046 87239.6 10000.0 110.104\nX-n561-k42 43338 43452.8 10000.0 55.41 43447 43492.4 10000.0 69.445\nX-n573-k30 51131 51234.8 10000.0 159.77 51096 51279.6 10000.0 189.324\nX-n599-k92 110043 110329.2 10000.0 434.99 109920 110276.4 10000.0 549.89\nX-n613-k62 60628 60823 10000.0 165.80 60733 60843 10000.0 212.619\nX-n627-k43 62800 63375.8 10000.0 273.62 63259 63506.4 10000.0 365.921\nX-n641-k35 64933 65068.2 10000.0 181.45 64703 64894.6 10000.0 237.72\nX-n655-k131 107094 107185.6 10000.0 70.09 107027 107080.6 10000.0 94.736\nX-n670-k126 147163 147671.4 10000.0 559.93 147398 147601.8 10000.0 758.066\nX-n685-k75 69575 69776.4 10000.0 250.66 69487 69682.4 10000.0 332.686\nX-n701-k44 83208 83449.6 10000.0 238.43 82975 83313 10000.0 267.65\nX-n716-k35 44340 44602.6 10000.0 273.29 44163 44405.8 10000.0 311.628\nX-n733-k159 137636 137904.6 10000.0 137.73 137339 137707.8 10000.0 211.729\nX-n749-k98 78899 79072 10000.0 463.61 78680 78984.8 10000.0 625.813\nX-n766-k71 115947 116142.2 10000.0 464.50 116190 116273.2 10000.0 674.712\nX-n783-k48 73737 74037.6 10000.0 327.30 73964 74081.4 10000.0 445.129\nX-n801-k40 73955 74128.6 10000.0 124.16 74068 74175.2 10000.0 172.678\nX-n819-k171 159950 160368 10000.0 622.68 159608 160135.6 10000.0 947.267\nX-n837-k142 195939 196219 10000.0 361.34 195706 196116.6 10000.0 477.691\nX-n856-k95 89713 89815 10000.0 62.60 89601 89700.4 10000.0 98.436\nX-n876-k59 100566 100755.8 10000.0 473.16 100710 100855.6 10000.0 658.698\nX-n895-k37 56535 56829.4 10000.0 662.29 56468 56981.4 10000.0 1029.72\nX-n916-k207 331508 332316.4 10000.0 515.08 331326 331886.6 10000.0 889.181\nX-n936-k151 134611 135110.2 10000.0 417.54 134379 134698.2 10000.0 649.151\nX-n957-k87 86226 86460.2 10000.0 94.54 86294 86453.8 10000.0 154.913\nX-n979-k58 120134 121165.8 10000.0 1051.82 121083 121713.2 10000.0 1506.112\nX-n1001-k43 74275 74479.4 10000.0 250.94 74204 74491.6 10000.0 362.494\nleading the algorithm to escape from local optima effec-\ntively. Thus, our learning method shows better performance\nthan existing ones for TSP.\n5.4. Ablation Study\nWe perform two groups of ablation studies to evaluate\nthe effect of components in our method. The first groupfocuses on the arm selection strategies by comparing ban-\ndLKH with its three variants, bandLKH-no ğœ–, bandLKH-\nnoğ‘€, and bandLKH-no ğ›¼, which remove the ğœ–-greedy,ğ‘€-\ngreedy, and ğ›¼-greedy strategies from bandLKH, respec-\ntively.ThesecondgroupfocusesontheMABmodelbycom-\nparing bandLKH with a variant algorithm of LKH, LKH-\nğ¶ğ‘šğ‘ğ‘¥, which sets the maximum capacity of each candidate\ntoğ¶ğ‘šğ‘ğ‘¥= 7and regards all the edges of each candidate\nset as candidate edges. The ablation studies are performed\nWang et al.: Preprint submitted to Elsevier Page 9 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\nTable 7\nDetailed comparison of LKH3 and bandLKH-3 on MTSP. The best results appear in bold.\nInstanceLKH3 bandLKH-3InstanceLKH3 bandLKH-3\nBest Average Trials Time (s) Best Average Trials Time (s) Best Average Trials Time (s) Best Average Trials Time (s)\neil101 646 646 128.0 0.00 646 646 114.0 0.00 u574 37012 37113 1000.0 0.09 37030 37168 1000.0 0.11\nlin105 14741 14741 1.0 0.00 14741 14741 1.0 0.00 rat575 6821 6850.6 1000.0 0.09 6832 6850.6 1000.0 0.11\npr107 44869 44869 1.0 0.00 44869 44869 1.0 0.00 p654 36890 37413.6 975.2 0.13 36890 36897.67 800.3 0.10\ngr120 7196 7196 133.0 0.00 7196 7196 465.0 0.01 d657 54422 54697.8 1000.0 0.11 54396 54521.4 1000.0 0.13\npr124 59979 59979 77.0 0.00 59979 59979 53.0 0.00 gr666 300910 301704.8 1000.0 0.12 301747 302599.4 1000.0 0.14\nbier127 119163 119163 87.0 0.00 119163 119163 45.0 0.00 u724 42599 42788.8 1000.0 0.12 42719 42784.8 1000.0 0.14\nch130 6296 6296 193.0 0.01 6296 6296 228.0 0.01 rat783 8902 8916.2 1000.0 0.13 8873 8906 1000.0 0.16\npr136 98629 98740 1000.0 0.02 98629 98629 628.0 0.01 dsj1000 18780343 18840808.2 1000.0 0.22 18809451 18830484.2 1000.0 0.29\ngr137 73410 73410 33.0 0.00 73410 73410 1.0 0.00 pr1002 264134 265246.4 1000.0 0.18 265713 266412 1000.0 0.22\npr144 59444 59444 19.0 0.00 59444 59444 19.0 0.00 si1032 93045 93101.2 1000.0 0.19 92959 93025 1000.0 0.23\nch150 6571 6589.67 816.3 0.02 6571 6571 371.0 0.01 u1060 225648 226778.4 1000.0 0.22 225759 226196.4 1000.0 0.28\nkroA150 26943 26943 1.0 0.00 26943 26943 11.0 0.00 vm1084 241570 242288.2 1000.0 0.21 242063 242842 1000.0 0.27\nkroB150 26476 26476 647.0 0.01 26476 26476 937.0 0.01 pcb1173 57880 57942 1000.0 0.21 57660 57861.4 1000.0 0.28\npr152 75893 75893 75.0 0.01 75893 75893 308.0 0.01 d1291 56320 56390.6 1000.0 0.24 56541 56819.4 1000.0 0.31\nu159 43846 43846 12.0 0.00 43846 43846 1.0 0.00 rl1304 257894 262147 1000.0 0.26 254936 255536.4 1000.0 0.34\nsi175 21717 21725.4 834.2 0.05 21717 21723.5 570.5 0.02 rl1323 274672 278159.6 1000.0 0.26 273005 274332.8 1000.0 0.34\nbrg180 1980 1980 90.0 0.00 1980 1980 99.0 0.01 nrw1379 57099 57207.4 1000.0 0.29 57001 57165.2 1000.0 0.41\nrat195 2381 2385.33 1000.0 0.02 2381 2385.8 1000.0 0.05 fl1400 21294 21515.4 1000.0 0.41 21094 21119.6 1000.0 0.58\nd198 20351 20351 282.0 0.01 20351 20351.5 582.5 0.02 u1432 154056 154629.2 1000.0 0.32 154319 154480 1000.0 0.41\nkroA200 29538 29547.33 891.7 0.02 29552 29552 1000.0 0.05 fl1577 22574 23266.8 1000.0 0.34 22603 22943 1000.0 0.43\nkroB200 29767 29767 56.0 0.01 29767 29788.75 957.0 0.04 d1655 68582 68937.4 1000.0 0.39 68826 69305.2 1000.0 0.53\ngr202 45838 45851.5 898.0 0.02 45838 45851.5 867.5 0.02 vm1748 343521 344526.4 1000.0 0.46 341308 342488 1000.0 0.64\nts225 128643 128643 115.0 0.01 128643 128643 121.0 0.01 u1817 58222 58310 1000.0 0.44 58120 58307 1000.0 0.55\ntsp225 3988 4009.67 716.7 0.03 3988 3988 703.0 0.01 rl1889 324006 324944.2 1000.0 0.50 320878 325690.8 1000.0 0.68\ngr229 137521 137935 1000.0 0.06 137357 137780 1000.0 0.07 d2103 85852 86378.6 1000.0 0.49 85786 86333.6 1000.0 0.60\ngil262 2447 2453.8 1000.0 0.04 2447 2450 1000.0 0.06 u2152 65025 65179.2 1000.0 0.61 65410 65660 1000.0 0.82\npr264 49947 50010.4 1000.0 0.04 49704 49738 906.5 0.02 u2319 235352 235563.8 1000.0 0.72 235779 235879.2 1000.0 0.90\na280 2645 2645 417.0 0.01 2645 2656.5 581.0 0.02 pr2392 384311 386713 1000.0 0.69 383045 384996.6 1000.0 0.88\npr299 48821 49071.8 1000.0 0.06 48889 49000.6 1000.0 0.07 pcb3038 140077 140308.2 1000.0 1.13 140125 140322.6 1000.0 1.41\nlin318 42391 42478 761.0 0.03 42412 42548.8 1000.0 0.07 fl3795 33249 33496 1000.0 1.62 32305 32902.4 1000.0 2.28\nlinhp318 41711 41768.2 1000.0 0.05 41748 41849 1000.0 0.07 fnl4461 185381 186091.4 1000.0 2.66 184933 185112.6 1000.0 4.09\nrd400 15355 15391.6 1000.0 0.07 15366 15395.2 1000.0 0.08 rl5915 599265 601361 1000.0 4.11 587629 590227.6 1000.0 7.20\nfl417 11941 12065.33 715.3 0.05 11941 11941.67 859.3 0.08 rl5934 593816 597851.4 1000.0 4.12 571066 586723.2 1000.0 5.81\ngr431 177596 177854.2 1000.0 0.08 177336 177643 1000.0 0.10 pla7397 24404268 24607606.6 1000.0 6.64 23928458 23991798.4 1000.0 11.33\npr439 108126 109305.2 1000.0 0.07 108126 108989.2 1000.0 0.09 rl11849 998816 1007830.4 10000.0 18.12 940468 942182 10000.0 50.34\npcb442 51071 51137 1000.0 0.07 51094 51318.4 1000.0 0.08 usa13509 20785341 21020059 10000.0 24.69 20252999 20329103.6 10000.0 66.72\nd493 42785 42876.6 1000.0 0.10 42753 42790 1000.0 0.11 brd14051 478611 483402.6 10000.0 27.83 474936 475305.2 10000.0 78.24\natt532 28310 28354 1000.0 0.10 28323 28340.2 1000.0 0.11 d15112 1604194 1604374.8 10000.0 32.08 1593905 1594424.8 10000.0 111.20\nali535 203472 205287 1000.0 0.11 203044 204406.8 1000.0 0.14 d18512 658656 659308 10000.0 49.86 654037 654150.8 10000.0 116.81\nsi535 48914 48966 1000.0 0.10 48907 48916.2 1000.0 0.13 pla33810 70686837 70769236.6 3000.0 177.45 68567400 68808980.6 3000.0 391.44\npa561 2817 2819.8 1000.0 0.12 2806 2812.6 1000.0 0.13 pla85900 166383078 166720326.8 3000.0 2042.30 157305820 158179771.8 3000.0 2769.29\nbasedonallthe75TSPLIBinstanceswhosenumberofcities\nranges from 101 to 10,000.\n5.4.1. Ablation Study on the Arm Selection Strategy\nDue to the limited space, we present summarized com-\nparisonresultsofbandLKHanditsvariants,bandLKH-no ğœ–,\nbandLKH-no ğ‘€,andbandLKH-no ğ›¼,inTable3,whererows\nğ‘Šğ‘–ğ‘›ğ‘ğ‘’ğ‘ ğ‘¡andğ‘Šğ‘–ğ‘›ğ‘ğ‘£ğ‘”indicate the number of instances in\nwhich the algorithm obtains better results of the best and\naveragesolutioninmultiplerunsthanitscompetitor,respec-\ntively, and rows ğºğ‘ğ‘ğ‘ğ‘’ğ‘ ğ‘¡andğºğ‘ğ‘ğ‘ğ‘£ğ‘”indicate the average\nvalues of the gap of the best and average solutions to the\noptimal solutions upon all the 75 instances, respectively.\nThe detailed results are referred to in the Appendix. The\nresults show that bandLKH generally outperforms the three\nvariants, indicating that our selected three arm selection\nstrategies are effective and complementary, and bandLKH\ncombines their complementarity to improve the robustness.\n5.4.2. Ablation Study on the MAB Model\nThe summarized comparison results between bandLKH\nwith LKH-ğ¶ğ‘šğ‘ğ‘¥are shown in Table 4. The results show\nthat bandLKH exhibits better performance and robustness\nthan LKH-ğ¶ğ‘šğ‘ğ‘¥in terms of the best and average solutions,\nindicatingthatdirectlyenlargingthecandidateedgesisalso\nnot a good choice since there might be some low-quality\nedges contained, and our MAB model can learn from the\nsearchprocessandsmartlyselectcandidateedgesandignore\nlow-qualityedgesintheenlargedcandidatesets,makingour\nbandLKH significantly outperform the LKH algorithm and\nalso show higher robustness than the LKH- ğ¶ğ‘šğ‘ğ‘¥algorithm\nwithout a smart filter.5.5. Generalization Evaluation on MTSP and\nCVRP\nFinally, we compare bandLKH-3 with LKH-3 in CVRP\nand MTSP and full results are presented in Table 5, Table 6\nand Table 7 respectively. As shown in full results corre-\nsponding to CVRP, bandLKH-3 shows better performance\nthan LKH-3 in most instances containing X-n101-k25, X-\nn289-k60, X-n480-k70 and X-n936-k151 .... In MTSP,\nbandLKH-3 also performs better than LKH-3 in medium\nand hard instances, such as ali535, rl1304, d2103, rl11849\nand pla85900, which shows that bandLKH-3 is suitable\nfor different scale of the problem. As time goes by, our\nproposed method could learn more beneficial information\nfrom passing trials so that guide algorithm to explore more\nsignificant search space.\nGenerally speaking, the results show that among all the\n82testedMTSPinstances,bandLKH-3obtainsbetterresults\nthan LKH-3 in 33 (resp. 47) instances in terms of the best\n(resp.average)solutionsandworseresultsthanLKH-3in21\n(resp.19)instancesintermsofthebest(resp.average)solu-\ntions.Amongallthe100testedCVRPinstances,bandLKH-\n3obtainsbetterresultsthanLKH-3in56(resp.61)instances\nin terms of the best (resp. average) solutions and worse\nresults than LKH-3 in 35 (resp. 35) instances in terms of\nthebest(resp.average)solutions.Theresultsalsoshowthat\nbandLKH-3 exhibits excellent performance in MTSP and\nCVRPinstancesacrossvariousscales.bandLKH-3exhibits\na general improvement over LKH-3 in MTSP and CVRP,\nandtheresultsindicatetheexcellentgeneralizationcapabil-\nity of our MAB method.\nWang et al.: Preprint submitted to Elsevier Page 10 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\n6. Conclusion\nSelectingappropriatecandidateedgesiscrucialforsolv-\ning various routing problems, which decides the new edges\nthat can be used to adjust solutions and explore the solution\nspace.Largercandidatesetsindicatewidersearchspaceand\nlower efficiency at the same time. Balancing the search ac-\ncuracyandefficiencyisthemagicofheuristicmethods.The\nLKHalgorithmachievesthisbytuningthecandidatesettoa\nreasonablesize.Inthiswork,weproposeanalternativemay,\ni.e., modeling the selection of candidate edges as pulling\narms in multi-armed bandits, providing opportunities for\nmore potential edges to be considered as candidate edges\nandlearningfromthesearchingprocesstoselectappropriate\ncandidate edges. Extensive comparisons, ablation studies,\nandevaluationsongeneralizationcapabilitydemonstratethe\neffectiveness of our proposed algorithm.\nThough multi-armed bandit is not a new technology,\nidentifying the limitations of LKH and combining the ban-\ndit model with the problem context to improve the local\nsearch algorithm is indeed of significant research value. In\nthe future, we will continue to refine bandLKH, such as\nadaptivelychangingthesizeofthecandidatesetstoenhance\nthe performance and robustness for problems in various\nscales. Also, our method has the potential to be extended\nto other routing problems, such as various variants of TSP\nand vehicle routing problems, that also need to select high-\nquality candidate edges.\nAcknowledgments\nThis work is supported by National Natural Science\nFoundation of China (U22B2017) and Microsoft Research\nAsia (100338928).\nReferences\n[1] MohammadRezaNazari,AfshinOroojlooy,LawrenceV.Snyder,and\nMartin TakÃ¡c. Reinforcement Learning for Solving the Vehicle\nRouting Problem. In Proceedings of the 31st Annual Conference on\nNeural Information Processing Systems , pages 9861â€“9871, 2018.\n[2] Zhouxing Su, Shihao Huang, Chungen Li, and Zhipeng LÃ¼. A\nTwo-Stage Matheuristic Algorithm for Classical Inventory Routing\nProblem. In Proceedings of the 29th International Joint Conference\non Artificial Intelligence , pages 3430â€“3436, 2020.\n[3] Yuan Jiang, Yaoxin Wu, Zhiguang Cao, and Jie Zhang. Learning to\nSolveRoutingProblemsviaDistributionallyRobustOptimization. In\nProceedings of the 36th AAAI Conference on Artificial Intelligence,\nthe 34th Conference on Innovative Applications of Artificial Intelli-\ngence,andthe12thSymposiumonEducationalAdvancesinArtificial\nIntelligence , pages 9786â€“9794, 2022.\n[4] Jingyang Zhao and Mingyu Xiao. The Linear Distance Traveling\nTournament Problem Allows an EPTAS. In Proceedings of the\n37thAAAIConferenceonArtificialIntelligence,the35thConference\non Innovative Applications of Artificial Intelligence, and the 13th\nSymposium on Educational Advances in Artificial Intelligenc , pages\n12155â€“12162, 2023.\n[5] Changhyun Kwon Sasan Mahmoudinazlou. A hybrid genetic algo-\nrithm for the minâ€“max multiple traveling salesman problem. Com-\nputers & Operations Research , 162:106455, 2024.\n[6] Qinghua Wu Yongliang Lu, Una Benlic. A population algorithm\nbased on randomized tabu thresholding for the multi-commoditypickup-and-delivery traveling salesman problem. Computers & Op-\nerations Research , 101:285â€“297, 2019.\n[7] Angelo Sifaleras Panagiotis Karakostas. The pollution traveling\nsalesmanproblemwithrefueling. Computers&OperationsResearch ,\n167:106661, 2024.\n[8] Gilbert Laporte David Canca, Eva Barrena. Arrival and service\ntime dependencies in the single-and multi-visit selective traveling\nsalesman problem. Computers & Operations Research , 166:106632,\n2024.\n[9] Yuichi Nagata and Shigenobu Kobayashi. A Powerful Genetic Al-\ngorithmUsingEdgeAssemblyCrossoverfortheTravelingSalesman\nProblem. INFORMS Journal on Computing , 25(2):346â€“363, 2013.\n[10] Xueshi Dong, Liwen Ma, Xin Zhao, Yongchang Shan, Jie Wang,\nand Zhenghao Xu. Hybrid genetic algorithm with wiener process\nfor multi-scale colored balanced traveling salesman problem. Expert\nSystems with Applications , 262, 2025.\n[11] Pablo GutiÃ©rrez-Aguirre and Carlos Contreras-Bolton. A multioper-\nator genetic algorithm for the traveling salesman problem with job-\ntimes.Expert Systems with Applications , 240, 2024.\n[12] Keld Helsgaun. An Effective Implementation of the Lin-Kernighan\nTraveling Salesman Heuristic. European Journal of Operational\nResearch, 126(1):106â€“130, 2000.\n[13] Shen Lin and Brian W. Kernighan. An Effective Heuristic Algo-\nrithm for the Traveling-Salesman Problem. Operations Research ,\n21(2):498â€“516, 1973.\n[14] Michael Held and Richard M. Karp. The Traveling-Salesman\nProblem and Minimum Spanning Trees. Operations Research ,\n18(6):1138â€“1162, 1970.\n[15] Jiongzhi Zheng, Kun He, Jianrong Zhou, Yan Jin, and Chu-Min Li.\nCombining Reinforcement Learning with Lin-Kernighan-Helsgaun\nAlgorithmfortheTravelingSalesmanProblem. In Proceedingsofthe\n35th AAAI conference on artificial intelligence, the 33rd Conference\non Innovative Applications of Artificial Intelligence, and the 11th\nSymposiumonEducationalAdvancesinArtificialIntelligence ,pages\n12445â€“12452, 2021.\n[16] Liang Xin, Wen Song, Zhiguang Cao, and Jie Zhang. NeuroLKH:\nCombining Deep Learning Model with Lin-Kernighan-Helsgaun\nHeuristic for Solving the Traveling Salesman Problem. In Proceed-\ningsofthe34thAdvancesinNeuralInformationProcessingSystems ,\npages 7472â€“7483, 2021.\n[17] Keld Helsgaun. An Extension of the Lin-Kernighan-Helsgaun TSP\nSolverforConstrainedTravelingSalesmanandVehicleRoutingProb-\nlems. Technical report, Roskilde University, 2017.\n[18] Yan Jin, Yuandong Ding, Xuanhao Pan, Kun He, Li Zhao, Tao\nQin, Lei Song, and Jiang Bian. Pointerformer: Deep Reinforced\nMulti-Pointer Transformer for the Traveling Salesman Problem. In\nProceedings of the 37th AAAI Conference on Artificial Intelligence,\nthe 35th Conference on Innovative Applications of Artificial Intelli-\ngence,andthe13thSymposiumonEducationalAdvancesinArtificial\nIntelligence , pages 8132â€“8140, 2023.\n[19] Xuanhao Pan, Yan Jin, Yuandong Ding, Mingxiao Feng, Li Zhao,\nLei Song, and Jiang Bian. Hierarchically Solving the Large-scale\nTravellingSalesmanProblem. In Proceedingsofthe37thAAAICon-\nference on Artificial Intelligence, the 35th Conference on Innovative\nApplications of Artificial Intelligence, and the 13th Symposium on\nEducational Advances in Artificial Intelligence , pages 9345â€“9353,\n2023.\n[20] Paulo R. de O. da Costa, Jason Rhuggenaath, Yingqian Zhang, and\nAlp Akcay. Learning 2-opt Heuristics for the Traveling Salesman\nProblem via Deep Reinforcement Learning. In Proceedings of the\n12th Asian Conference on Machine Learning , volume 129, pages\n465â€“480, 2020.\n[21] Jingyan Sui, Shizhe Ding, Ruizhi Liu, Liming Xu, and Dongbo\nBu. Learning 3-opt Heuristics for Traveling Salesman Problem via\nDeep Reinforcement Learning. In Proceedings of the 13th Asian\nConference on Machine Learning , volume 157, pages 1301â€“1316,\n2021.\nWang et al.: Preprint submitted to Elsevier Page 11 of 12\nBandit based Dynamic Candidate Edge Selection in Solving TSPs\n[22] YiningMa,ZhiguangCao,andYeowMengChee. Learningtosearch\nfeasible and infeasible regions of routing problems with flexible\nneural k-opt. Advances in Neural Information Processing Systems ,\n36, 2024.\n[23] Aigerim Bogyrbayeva, Taehyun Yoon, Hanbum Ko, Sungbin Lim,\nHyokun Yun, and Changhyun Kwon. A Deep Reinforcement Learn-\ning Approach for Solving the Traveling-Salesman Problem with\nDrone.Transportation Research Part C: Emerging Technologies ,\n148:103981, 2023.\n[24] Xavier Bresson and Thomas Laurent. The Transformer Network for\nthe Traveling-Salesman Problem. arXiv preprint arXiv:2103.03012 ,\n2021.\n[25] Syu-Ning Johnn, Victor-Alexandru Darvariu, Julia Handl, and JÃ¶rg\nKalcsics. A graph reinforcement learning framework for neural\nadaptive large neighbourhood search. Computers & Operations\nResearch, 172, 2024.\n[26] Elias B. Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and\nLe Song. Learning Combinatorial Optimization Algorithms over\nGraphs. In Proceedings of the 30th Annual Conference on Neural\nInformation Processing Systems , pages 6348â€“6358, 2017.\n[27] Yeong-Dae Kwon, Jinho Choo, Byoungjip Kim, Iljoo Yoon,\nYoungjune Gwon, and Seungjai Min. POMO: Policy Otimization\nwithMultipleOptimaforReinforcementLearning. In Proceedingsof\nthe 33rd Advances in Neural Information Processing Systems , pages\n33: 21188â€“21198, 2020.\n[28] Haoran Ye, Jiarui Wang, Helan Liang, Zhiguang Cao, Yong Li, and\nFanzhangLi. GLOP:LearningGlobalPartitionandLocalConstruc-\ntion for Solving Large-scale Routing Problems in Real-time. arXiv\npreprint arXiv , 2312:08224, 2023.\n[29] Nina Mazyavkina, Sergey Sviridov, Sergei Ivanov, and Evgeny Bur-\nnaev. Reinforcement Learning for Combinatorial Optimization: A\nSurvey.Computers & Operations Research , 134:105400, 2021.\n[30] Luca M Gambardella and Marco Dorigo. Ant-Q: A Reinforcement\nLearning Approach Traveling Salesman Problem. In Machine learn-\ning proceedings 1995 , pages 252â€“260. Elsevier, 1995.\n[31] Ruoying Sun, Shoji Tatsumi, and Gang Zhao. Multiagent Reinforce-\nment Learning Method with an Improved Ant Colony System. In\nProceedings of the IEEE International Conference on Systems, Man\n& Cybernetics , pages 1612â€“1617, 2001.\n[32] Fei Liu and Guangzhou Zeng. Study of Genetic Algorithm with\nReinforcement Learning to Solve the TSP. Expert Systems with\nApplications , 36(3):6995â€“7001, 2009.\n[33] YujiZou,,Jin-KaoHao,andQinghuaWu. Areinforcementlearning\nguidedhybridevolutionaryalgorithmforthelatencylocationrouting\nproblem. Computers & Operations Research , 170, 2024.\n[34] Florentin D. Hildebrandt, Barrett W. Thomas, and Marlin W. Ulmer.\nOpportunities for reinforcement learning in stochastic dynamic vehi-\ncle routing. Computers & Operations Research , 150, 2023.\n[35] Michael Held and Richard M. Karp. The Traveling-Salesman Prob-\nlem and Minimum Spanning Trees: Part II. Mathematical Program-\nming, 1(1):6â€“25, 1971.\n[36] Shivaram Kalyanakrishnan and Peter Stone. Efficient Selection of\nMultiple Bandit Arms: Theory and Practice. In Proceedings of the\n27thInternationalConferenceonMachineLearning ,pages511â€“518,\n2010.\n[37] Eduardo Uchoa, Diego Pecin, Artur Alves Pessoa, Marcus Poggi,\nThibaut Vidal, and Anand Subramanian. New benchmark instances\nfor the capacitated vehicle routing problem. European Journal of\nOperational Research , 257(3):845â€“858, 2017.\n[38] Marius Lindauer, Katharina Eggensperger, Matthias Feurer, AndrÃ©\nBiedenkapp, Difan Deng, Carolin Benjamins, Tim Ruhkopf, RenÃ©\nSass, and Frank Hutter. SMAC3: A Versatile Bayesian Optimization\nPackage for Hyperparameter Optimization. Journal of Machine\nLearning Research , 23(54):1â€“9, 2022.\nWang et al.: Preprint submitted to Elsevier Page 12 of 12"
  }
}